{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Detection with Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\Anaconda3\\envs\\bakalarka\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\marti\\Anaconda3\\envs\\bakalarka\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\marti\\Anaconda3\\envs\\bakalarka\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardio_dict = scipy.io.loadmat('cardio.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, written by Octave 3.8.0, 2014-12-18 10:48:09 UTC',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'X': array([[ 0.00491231,  0.69319077, -0.20364049, ...,  0.23149795,\n",
       "         -0.28978574, -0.49329397],\n",
       "        [ 0.11072935, -0.07990259, -0.20364049, ...,  0.09356344,\n",
       "         -0.25638541, -0.49329397],\n",
       "        [ 0.21654639, -0.27244466, -0.20364049, ...,  0.02459619,\n",
       "         -0.25638541,  1.14001753],\n",
       "        ...,\n",
       "        [-0.41835583, -0.91998844, -0.16463485, ..., -1.49268341,\n",
       "          0.24461959, -0.49329397],\n",
       "        [-0.41835583, -0.91998844, -0.15093411, ..., -1.42371616,\n",
       "          0.14441859, -0.49329397],\n",
       "        [-0.41835583, -0.91998844, -0.20364049, ..., -1.28578165,\n",
       "          3.58465295, -0.49329397]]),\n",
       " 'y': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardio_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cardio_dict['X']\n",
    "y = cardio_dict['y'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of input example: 21\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = X.shape[1]\n",
    "print(f'Size of input example: {INPUT_SIZE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the dataset into inliers and outliers:\n",
    "- only inliers are used for trainig the autoencoders\n",
    "- outliers are then mixed with the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inliers: 1655, Number of outliers: 176\n"
     ]
    }
   ],
   "source": [
    "X_inliers = X[y==0]\n",
    "y_inliers = np.zeros(len(X_inliers), dtype=int)\n",
    "X_outliers = X[y==1]\n",
    "y_outliers = np.ones(len(X_outliers), dtype=int)\n",
    "print(f'Number of inliers: {len(y_inliers)}, Number of outliers: {len(y_outliers)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the inliers into training, validation, and testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_inliers, y_inliers, test_size=0.20, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=1) # 0.2 x 0.8 = 0.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add outliers only to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.concatenate((X_test, X_outliers), axis=0)\n",
    "y_test = np.concatenate((y_test, y_outliers), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 1059 examples\n",
      "Validation set: 265 examples\n",
      "Testing set: 507 examples; inliers: 331, outliers: 176\n"
     ]
    }
   ],
   "source": [
    "print(f'Training set: {len(y_train)} examples')\n",
    "print(f'Validation set: {len(y_val)} examples')\n",
    "print(f'Testing set: {len(y_test)} examples; inliers: {np.sum(y_test==0)}, outliers: {np.sum(y_test==1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1059, 21)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataset and DataLoader instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardioDataset(Dataset):\n",
    "    def __init__(self, data: np.ndarray, labels: np.ndarray):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[np.ndarray, np.int32]:\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CardioDataset(X_train, y_train)\n",
    "val_data = CardioDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a general tuning framework, I will compare the following parameters for each of the architectures:\n",
    "- Batch size: 32, 64\n",
    "- Learning rate: 1e-3, 1e-2\n",
    "- Number of Encoder/Decoder Layers: 2, 3\n",
    "- Latent space dimension: 10, 12, 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model: nn.Module, optimizer: torch.optim.Optimizer, criterion: nn.MSELoss, train_loader: DataLoader):\n",
    "    '''\n",
    "    Train one epoch of the model on training dataset batched by the train_loader.\n",
    "    \n",
    "    :param nn.Module model: model on which we perform one training epoch\n",
    "    :param torch.optim.Optimizer optimizer: optimizer, e.g. ADAM or SGD\n",
    "    :param nn.MSELoss criterion: loss function used for training\n",
    "    :param DataLoader train_loader: data object for batching training set\n",
    "    :returns: an average loss on the training dataset\n",
    "    '''\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, _ = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs.float(), inputs.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: nn.Module, model_name: str, optimizer: torch.optim.Optimizer, criterion: nn.MSELoss,\n",
    "                train_loader: DataLoader, val_loader: DataLoader, nr_of_epochs: int = 100):\n",
    "    '''\n",
    "    Train the specified model, and evaluate on validation data.\n",
    "        \n",
    "    :param nn.Module model: model being trained\n",
    "    :param str model_name: model name, e.g. denoising_autoencoder\n",
    "    :param torch.optim.Optimizer optimizer: optimizer, e.g. ADAM or SGD\n",
    "    :param nn.MSELoss criterion: loss function used for training\n",
    "    :param DataLoader train_loader: data object for batching the training set\n",
    "    :param DataLoader val_loader: data object for batching the validation set\n",
    "    :param int nr_of_epochs: number of training epochs\n",
    "    '''\n",
    "    best_loss = 10**12\n",
    "    best_model, model_path, best_epoch = None, None, None\n",
    "\n",
    "    for epoch in range(nr_of_epochs):\n",
    "        model.train()\n",
    "        train_loss = train_one_epoch(model, optimizer, criterion, train_loader)\n",
    "        model.eval()\n",
    "\n",
    "        # performance on validation set\n",
    "        valid_loss = 0.0\n",
    "        for i, data in enumerate(val_loader):\n",
    "            inputs, _ = data\n",
    "            outputs = model(inputs.float())\n",
    "            loss = criterion(outputs.float(), inputs.float())\n",
    "            valid_loss += loss.item()\n",
    "        valid_loss = valid_loss / len(val_loader)\n",
    "\n",
    "        # logging at each Nth epoch\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'epoch {epoch + 1}; train loss: {train_loss}; valid loss: {valid_loss}')\n",
    "        \n",
    "        # remember model with the best validation loss\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_model = model.state_dict()\n",
    "            best_epoch = epoch + 1\n",
    "\n",
    "    # save the overall best model\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    os.makedirs('models/', exist_ok=True)\n",
    "    model_path = f'models/model_{model_name}_{timestamp}_epoch{best_epoch}'\n",
    "    torch.save(best_model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_testset(model: nn.Module, testset: np.ndarray, test_labels: np.ndarray) -> Tuple[pd.DataFrame, np.ndarray]:\n",
    "    '''\n",
    "    Evaluate testing data on the model, calculate reconstruction error, print statistics on inliers and outliers\n",
    "        \n",
    "    :param nn.Module model: model being evaluated\n",
    "    :param np.ndarray testset: testing inputs\n",
    "    :param np.ndarray test_labels: ground-truth labels\n",
    "    :returns: dataframe with reconstruction errors and classes, reconstrution errors\n",
    "    '''\n",
    "    testset_tensor = torch.tensor(testset).float()\n",
    "    reconstructed_test = model(testset_tensor)\n",
    "    mse_test = torch.sum((reconstructed_test.detach() - testset_tensor) ** 2, axis=1)\n",
    "    error_df = pd.DataFrame({'Reconstruction Error': mse_test, 'class': y_test})\n",
    "    \n",
    "    display(error_df[error_df['class'] == 0].describe())\n",
    "    display(error_df[error_df['class'] == 1].describe())\n",
    "    return error_df, mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_by_error(MSEs: np.ndarray, thres: float) -> np.ndarray:\n",
    "    '''\n",
    "    Classify an array of reconstruction errors w.r.t. a threshold\n",
    "    \n",
    "    :param np.ndarray MSEs: mean squared reconstruction errors\n",
    "    :param float thres: threshold of reconstruction error between inliers and outliers\n",
    "    :returns: binary array of class ids; 0 = inlier, 1 = outlier\n",
    "    '''\n",
    "    return np.array(MSEs > thres, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confusion_mat: np.ndarray):\n",
    "    '''\n",
    "    Plot a confusion matrix of true vs predicted labels.\n",
    "    \n",
    "    :param np.ndarray confusion_mat: confusion matrix between true and predicted labels\n",
    "    '''\n",
    "    class_labels = ['Inlier', 'Outlier']\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(confusion_mat, xticklabels=class_labels, yticklabels=class_labels, annot=True, fmt=\"d\", annot_kws={\"size\": 14});\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.ylabel('True class')\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_threshold_grid(MSEs: np.ndarray, true_labels: np.ndarray, model_name: str, start: float = 0.0, stop: float = 5.0, num_thresholds: int = 10, verbose: bool = True) -> float:\n",
    "    '''\n",
    "    Plot a confusion matrix of true vs predicted labels.\n",
    "    \n",
    "    :param np.ndarray MSEs: mean squared reconstruction errors on testing set\n",
    "    :param np.ndarray true_labels: ground-truth labels\n",
    "    :param str model_name: model name, e.g. denoising_autoencoder\n",
    "    :param float start: start of threshold interval\n",
    "    :param float stop: end of threshold interval\n",
    "    :param int num_thresholds: number of thresholds tested in the interval\n",
    "    :returns: threshold with the highest anomaly f1-score\n",
    "    '''\n",
    "    best_threshold = None\n",
    "    best_f1 = 0.0\n",
    "    display(Markdown(f'#### Model: {model_name}, trying {num_thresholds} thresholds from [{start}, {stop}]'))\n",
    "    if not verbose:\n",
    "        display(Markdown('For more detail, call the function with `verbose=True`'))\n",
    "        \n",
    "    for threshold in np.linspace(start, stop, num=num_thresholds):\n",
    "        predictions = classify_by_error(MSEs, threshold)\n",
    "        matrix = confusion_matrix(true_labels, predictions)\n",
    "        class_accuracies = matrix.diagonal()/matrix.sum(axis=1)\n",
    "        acc_df = pd.DataFrame({\n",
    "            'Inliers Accuracy': [class_accuracies[0]], \n",
    "            'Outliers Accuracy': [class_accuracies[1]], \n",
    "            'Overall Accuracy': [accuracy_score(true_labels, predictions)]\n",
    "        })\n",
    "        \n",
    "        outlier_f1 = f1_score(true_labels, predictions)\n",
    "        if outlier_f1 > best_f1:\n",
    "            best_f1 = outlier_f1\n",
    "            best_threshold = threshold\n",
    "        \n",
    "        if verbose:\n",
    "            display(Markdown(f'### Threshold {threshold}'))\n",
    "            display(acc_df.style.hide_index())\n",
    "            display(Markdown(f'##### Classification Report'))\n",
    "            print(classification_report(true_labels, predictions))\n",
    "            # plot_confusion_matrix(matrix)\n",
    "            display(Markdown('---'))\n",
    "    \n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Undercomplete AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE_UAE = 16\n",
    "LATENT_SIZE_UAE = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UndercompleteAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UndercompleteAutoEncoder, self).__init__()\n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Linear(INPUT_SIZE, HIDDEN_SIZE_UAE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_SIZE_UAE, LATENT_SIZE_UAE),\n",
    "        )\n",
    "        self.decode = nn.Sequential(\n",
    "            nn.Linear(LATENT_SIZE_UAE, HIDDEN_SIZE_UAE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_SIZE_UAE, INPUT_SIZE),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.encode(x)\n",
    "        x = self.decode(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_uae = DataLoader(train_data, batch_size=64, shuffle=False)\n",
    "val_dataloader_uae = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "\n",
    "undercomplete_ae = UndercompleteAutoEncoder()\n",
    "\n",
    "learning_rate_uae = 1e-2\n",
    "optimizer_uae = torch.optim.Adam(undercomplete_ae.parameters(), lr=learning_rate_uae)\n",
    "criterion_uae = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; train loss: 0.10081244435380488; valid loss: 0.08502055928111077\n",
      "epoch 20; train loss: 0.04724344435860129; valid loss: 0.03907952606678009\n",
      "epoch 30; train loss: 0.03061375131501871; valid loss: 0.026724489964544774\n",
      "epoch 40; train loss: 0.02637475115411422; valid loss: 0.022223379649221896\n",
      "epoch 50; train loss: 0.024052016108351594; valid loss: 0.019992296025156973\n",
      "epoch 60; train loss: 0.022681079530978903; valid loss: 0.019035288132727146\n",
      "epoch 70; train loss: 0.02128586227841237; valid loss: 0.017235860135406254\n",
      "epoch 80; train loss: 0.021138860515373593; valid loss: 0.0166503943502903\n",
      "epoch 90; train loss: 0.021212523912682253; valid loss: 0.01652503861114383\n",
      "epoch 100; train loss: 0.020280673880787456; valid loss: 0.016050476394593716\n",
      "epoch 110; train loss: 0.020473144181510982; valid loss: 0.016268335934728383\n",
      "epoch 120; train loss: 0.020555091254851398; valid loss: 0.016842686105519533\n",
      "epoch 130; train loss: 0.02054575934787007; valid loss: 0.017177290469408035\n",
      "epoch 140; train loss: 0.020267104291740584; valid loss: 0.01862733531743288\n",
      "epoch 150; train loss: 0.018078955219072455; valid loss: 0.018892413191497325\n",
      "epoch 160; train loss: 0.016736882190932247; valid loss: 0.01738448003306985\n",
      "epoch 170; train loss: 0.016411958919728502; valid loss: 0.01665173573419452\n",
      "epoch 180; train loss: 0.014225769459324725; valid loss: 0.015532363858073949\n",
      "epoch 190; train loss: 0.013938796870848712; valid loss: 0.015309752337634564\n",
      "epoch 200; train loss: 0.0141645262894385; valid loss: 0.015377685334533453\n"
     ]
    }
   ],
   "source": [
    "train_model(model=undercomplete_ae, model_name='undercomplete_autoencoder', optimizer=optimizer_uae, criterion=criterion_uae,\n",
    "            train_loader=train_dataloader_uae, val_loader=val_dataloader_uae, nr_of_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reconstruction Error</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>331.000000</td>\n",
       "      <td>331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.990230</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.113153</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.019305</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.096213</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.174489</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.391506</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>202.270462</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reconstruction Error  class\n",
       "count            331.000000  331.0\n",
       "mean               0.990230    0.0\n",
       "std               11.113153    0.0\n",
       "min                0.019305    0.0\n",
       "25%                0.096213    0.0\n",
       "50%                0.174489    0.0\n",
       "75%                0.391506    0.0\n",
       "max              202.270462    0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reconstruction Error</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.673295</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>61.410690</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.062788</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.846167</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.434397</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.873788</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>464.215851</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reconstruction Error  class\n",
       "count            176.000000  176.0\n",
       "mean              15.673295    1.0\n",
       "std               61.410690    0.0\n",
       "min                0.062788    1.0\n",
       "25%                0.846167    1.0\n",
       "50%                2.434397    1.0\n",
       "75%                4.873788    1.0\n",
       "max              464.215851    1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df, test_MSEs = eval_on_testset(undercomplete_ae, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Model: undercomplete_autoencoder, trying 40 thresholds from [0.1, 2.0]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "For more detail, call the function with `verbose=True`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimal_threshold_under = try_threshold_grid(test_MSEs, y_test, 'undercomplete_autoencoder', start=0.1, stop=2.0, num_thresholds=40, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Best Threshold 0.5384615384615384"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_34bb8309_d563_11ec_a89e_2016b948faac\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Inliers Accuracy</th>        <th class=\"col_heading level0 col1\" >Outliers Accuracy</th>        <th class=\"col_heading level0 col2\" >Overall Accuracy</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_34bb8309_d563_11ec_a89e_2016b948faacrow0_col0\" class=\"data row0 col0\" >0.836858</td>\n",
       "                        <td id=\"T_34bb8309_d563_11ec_a89e_2016b948faacrow0_col1\" class=\"data row0 col1\" >0.840909</td>\n",
       "                        <td id=\"T_34bb8309_d563_11ec_a89e_2016b948faacrow0_col2\" class=\"data row0 col2\" >0.838264</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b906a240d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Classification Report"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.87       331\n",
      "           1       0.73      0.84      0.78       176\n",
      "\n",
      "    accuracy                           0.84       507\n",
      "   macro avg       0.82      0.84      0.83       507\n",
      "weighted avg       0.85      0.84      0.84       507\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = classify_by_error(test_MSEs, optimal_threshold_under)\n",
    "matrix = confusion_matrix(y_test, predictions)\n",
    "class_accuracies = matrix.diagonal()/matrix.sum(axis=1)\n",
    "acc_df = pd.DataFrame({\n",
    "    'Inliers Accuracy': [class_accuracies[0]], \n",
    "    'Outliers Accuracy': [class_accuracies[1]], \n",
    "    'Overall Accuracy': [accuracy_score(y_test, predictions)]\n",
    "})\n",
    "\n",
    "display(Markdown(f'#### Best Threshold {optimal_threshold_under}'))\n",
    "display(acc_df.style.hide_index())\n",
    "display(Markdown(f'##### Classification Report'))\n",
    "print(classification_report(y_test, predictions))\n",
    "plot_confusion_matrix(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Denoising AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE_DAE = 16\n",
    "LATENT_SIZE_DAE = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingAutoEncoder(nn.Module):\n",
    "    def __init__(self, noise_rate):\n",
    "        super(DenoisingAutoEncoder, self).__init__()\n",
    "        self.noise_rate = noise_rate\n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Linear(INPUT_SIZE, HIDDEN_SIZE_DAE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_SIZE_DAE, LATENT_SIZE_DAE),\n",
    "        )\n",
    "        self.decode = nn.Sequential(\n",
    "            nn.Linear(LATENT_SIZE_DAE, HIDDEN_SIZE_DAE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_SIZE_DAE, INPUT_SIZE),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.training:\n",
    "            # randn_like returns tensor the same shape as x with random numbers\n",
    "            # from a normal distribution with mean 0 and variance 1\n",
    "            x = x + torch.randn_like(x) * self.noise_rate\n",
    "        x = self.encode(x)\n",
    "        x = self.decode(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_dae = DataLoader(train_data, batch_size=64, shuffle=False)\n",
    "val_dataloader_dae = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "\n",
    "denoising_ae = DenoisingAutoEncoder(noise_rate=0.1)\n",
    "\n",
    "learning_rate_dae = 1e-2\n",
    "optimizer_dae = torch.optim.Adam(denoising_ae.parameters(), lr=learning_rate_dae)\n",
    "criterion_dae = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; train loss: 0.11050024058888941; valid loss: 0.08543946072459221\n",
      "epoch 20; train loss: 0.05681239243815927; valid loss: 0.04110519923269749\n",
      "epoch 30; train loss: 0.04271755148382748; valid loss: 0.03197681121528149\n",
      "epoch 40; train loss: 0.03673059811048648; valid loss: 0.025821131095290183\n",
      "epoch 50; train loss: 0.03366892346564461; valid loss: 0.024151788279414176\n",
      "epoch 60; train loss: 0.032242374713806546; valid loss: 0.02117132507264614\n",
      "epoch 70; train loss: 0.032106141504995966; valid loss: 0.0210583521053195\n",
      "epoch 80; train loss: 0.030765031957451033; valid loss: 0.02000258192420006\n",
      "epoch 90; train loss: 0.0304722084718592; valid loss: 0.019853978604078292\n",
      "epoch 100; train loss: 0.030208943302140516; valid loss: 0.01919095143675804\n",
      "epoch 110; train loss: 0.029725811718141332; valid loss: 0.020026294328272343\n",
      "epoch 120; train loss: 0.02862738226266468; valid loss: 0.018690706044435502\n",
      "epoch 130; train loss: 0.02914551689344294; valid loss: 0.019157924503087998\n",
      "epoch 140; train loss: 0.02686892362201915; valid loss: 0.01902215275913477\n",
      "epoch 150; train loss: 0.025003171142409828; valid loss: 0.017100119777023793\n",
      "epoch 160; train loss: 0.025336992105140406; valid loss: 0.017903222888708114\n",
      "epoch 170; train loss: 0.023681472877369207; valid loss: 0.016849938593804837\n",
      "epoch 180; train loss: 0.0216340852134368; valid loss: 0.01665473710745573\n",
      "epoch 190; train loss: 0.02083064429461956; valid loss: 0.01502839159220457\n",
      "epoch 200; train loss: 0.020226366872734883; valid loss: 0.014686820097267628\n"
     ]
    }
   ],
   "source": [
    "train_model(model=denoising_ae, model_name='denoising_autoencoder', optimizer=optimizer_dae, criterion=criterion_dae,\n",
    "            train_loader=train_dataloader_dae, val_loader=val_dataloader_dae, nr_of_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reconstruction Error</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>331.000000</td>\n",
       "      <td>331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.929822</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.967920</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.032932</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.105756</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.183746</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.372330</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>181.372162</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reconstruction Error  class\n",
       "count            331.000000  331.0\n",
       "mean               0.929822    0.0\n",
       "std                9.967920    0.0\n",
       "min                0.032932    0.0\n",
       "25%                0.105756    0.0\n",
       "50%                0.183746    0.0\n",
       "75%                0.372330    0.0\n",
       "max              181.372162    0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reconstruction Error</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18.280983</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>55.621185</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.121286</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.855274</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.633982</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.062162</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>410.286560</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reconstruction Error  class\n",
       "count            176.000000  176.0\n",
       "mean              18.280983    1.0\n",
       "std               55.621185    0.0\n",
       "min                0.121286    1.0\n",
       "25%                0.855274    1.0\n",
       "50%                2.633982    1.0\n",
       "75%                7.062162    1.0\n",
       "max              410.286560    1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df, test_MSEs = eval_on_testset(denoising_ae, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Model: denoising_autoencoder, trying 40 thresholds from [0.1, 2.0]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "For more detail, call the function with `verbose=True`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimal_threshold_denoising = try_threshold_grid(test_MSEs, y_test, 'denoising_autoencoder', start=0.1, stop=2.0, num_thresholds=40, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Best Threshold 0.5384615384615384"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_5956ad6a_d563_11ec_ae25_2016b948faac\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Inliers Accuracy</th>        <th class=\"col_heading level0 col1\" >Outliers Accuracy</th>        <th class=\"col_heading level0 col2\" >Overall Accuracy</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_5956ad6a_d563_11ec_ae25_2016b948faacrow0_col0\" class=\"data row0 col0\" >0.839879</td>\n",
       "                        <td id=\"T_5956ad6a_d563_11ec_ae25_2016b948faacrow0_col1\" class=\"data row0 col1\" >0.869318</td>\n",
       "                        <td id=\"T_5956ad6a_d563_11ec_ae25_2016b948faacrow0_col2\" class=\"data row0 col2\" >0.850099</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b902da65e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Classification Report"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.84      0.88       331\n",
      "           1       0.74      0.87      0.80       176\n",
      "\n",
      "    accuracy                           0.85       507\n",
      "   macro avg       0.83      0.85      0.84       507\n",
      "weighted avg       0.86      0.85      0.85       507\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = classify_by_error(test_MSEs, optimal_threshold_denoising)\n",
    "matrix = confusion_matrix(y_test, predictions)\n",
    "class_accuracies = matrix.diagonal()/matrix.sum(axis=1)\n",
    "acc_df = pd.DataFrame({\n",
    "    'Inliers Accuracy': [class_accuracies[0]], \n",
    "    'Outliers Accuracy': [class_accuracies[1]], \n",
    "    'Overall Accuracy': [accuracy_score(y_test, predictions)]\n",
    "})\n",
    "\n",
    "display(Markdown(f'#### Best Threshold {optimal_threshold_denoising}'))\n",
    "display(acc_df.style.hide_index())\n",
    "display(Markdown(f'##### Classification Report'))\n",
    "print(classification_report(y_test, predictions))\n",
    "plot_confusion_matrix(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Variational AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Altered training and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch_VAE(model: nn.Module, optimizer: torch.optim.Optimizer, criterion: nn.MSELoss, train_loader: DataLoader):\n",
    "    '''\n",
    "    Train one epoch of the model on training dataset batched by the train_loader.\n",
    "    \n",
    "    :param nn.Module model: model on which we perform one training epoch\n",
    "    :param torch.optim.Optimizer optimizer: optimizer, e.g. ADAM or SGD\n",
    "    :param nn.MSELoss criterion: loss function used for training\n",
    "    :param DataLoader train_loader: data object for batching training set\n",
    "    :returns: an average loss on the training dataset\n",
    "    '''\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, _ = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs.float())\n",
    "        loss = ((outputs.float() - inputs.float()) ** 2).mean() + model.kl\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_VAE(model: nn.Module, model_name: str, optimizer: torch.optim.Optimizer, criterion: nn.MSELoss, \n",
    "                    train_loader: DataLoader, val_loader: DataLoader, nr_of_epochs: int = 100):\n",
    "    '''\n",
    "    Train the specified model, and evaluate on validation data.\n",
    "        \n",
    "    :param nn.Module model: model being trained\n",
    "    :param str model_name: model name, e.g. denoising_autoencoder\n",
    "    :param torch.optim.Optimizer optimizer: optimizer, e.g. ADAM or SGD\n",
    "    :param nn.MSELoss criterion: loss function used for training\n",
    "    :param DataLoader train_loader: data object for batching the training set\n",
    "    :param DataLoader val_loader: data object for batching the validation set\n",
    "    :param int nr_of_epochs: number of training epochs\n",
    "    '''\n",
    "    best_loss = 10**12\n",
    "    best_model, model_path, best_epoch = None, None, None\n",
    "\n",
    "    for epoch in range(nr_of_epochs):\n",
    "        model.train()\n",
    "        train_loss = train_one_epoch_VAE(model, optimizer, criterion, train_loader)\n",
    "        model.eval()\n",
    "\n",
    "        # performance on validation set\n",
    "        with torch.no_grad():\n",
    "            valid_loss = 0.0\n",
    "            for i, data in enumerate(val_loader):\n",
    "                inputs, _ = data\n",
    "                outputs = model(inputs.float())\n",
    "                loss = ((outputs.float() - inputs.float()) ** 2).mean() + model.kl\n",
    "                valid_loss += loss.item()\n",
    "            valid_loss = valid_loss / len(val_loader)\n",
    "\n",
    "            # logging at each Nth epoch\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f'epoch {epoch + 1}; train loss: {train_loss}; valid loss: {valid_loss}')\n",
    "\n",
    "            # remember model with the best validation loss\n",
    "            if valid_loss < best_loss:\n",
    "                best_loss = valid_loss\n",
    "                best_model = model.state_dict()\n",
    "                best_epoch = epoch + 1\n",
    "\n",
    "    # save the overall best model\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    os.makedirs('models/', exist_ok=True)\n",
    "    model_path = f'models/model_{model_name}_{timestamp}_epoch{best_epoch}'\n",
    "    torch.save(best_model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_testset_VAE(model: nn.Module, testset: np.ndarray, test_labels: np.ndarray) -> Tuple[pd.DataFrame, np.ndarray]:\n",
    "    '''\n",
    "    Evaluate testing data on the model, calculate reconstruction error, print statistics on inliers and outliers\n",
    "        \n",
    "    :param nn.Module model: model being evaluated\n",
    "    :param np.ndarray testset: testing inputs\n",
    "    :param np.ndarray test_labels: ground-truth labels\n",
    "    :returns: dataframe with reconstruction errors and classes, reconstrution errors\n",
    "    '''\n",
    "    testset_tensor = torch.tensor(testset).float()\n",
    "    reconstructed_test = model(testset_tensor)\n",
    "    mse_test = torch.mean((reconstructed_test.detach() - testset_tensor) ** 2, axis=1) + model.kl\n",
    "    error_df = pd.DataFrame({'Reconstruction Error': mse_test, 'class': y_test})\n",
    "    \n",
    "    display(error_df[error_df['class'] == 0].describe())\n",
    "    display(error_df[error_df['class'] == 1].describe())\n",
    "    return error_df, mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE_VAE = 16\n",
    "LATENT_SIZE_VAE = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VariationalAutoEncoder, self).__init__()\n",
    "        self.encLin1 = nn.Linear(INPUT_SIZE, HIDDEN_SIZE_VAE)\n",
    "        self.reluEnc = nn.ReLU()\n",
    "        self.encLin21 = nn.Linear(HIDDEN_SIZE_VAE, LATENT_SIZE_VAE)\n",
    "        self.encLin22 = nn.Linear(HIDDEN_SIZE_VAE, LATENT_SIZE_VAE)\n",
    "        self.normal = torch.distributions.Normal(0, 1)\n",
    "        self.kl = 0\n",
    "        \n",
    "        self.decLin1 = nn.Linear(LATENT_SIZE_VAE, HIDDEN_SIZE_VAE)\n",
    "        self.reluDec = nn.ReLU()\n",
    "        self.decLin2 = nn.Linear(HIDDEN_SIZE_VAE, INPUT_SIZE)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.reluEnc(self.encLin1(x))\n",
    "        mu = self.encLin21(x)\n",
    "        sigma = torch.exp(self.encLin22(x))\n",
    "        z = mu + sigma * self.normal.sample(mu.shape)\n",
    "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).mean()\n",
    "\n",
    "        x = self.reluDec(self.decLin1(z))\n",
    "        x = self.decLin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_vae = DataLoader(train_data, batch_size=64, shuffle=False)\n",
    "val_dataloader_vae = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "\n",
    "variational_ae = VariationalAutoEncoder()\n",
    "\n",
    "learning_rate_vae = 1e-2\n",
    "optimizer_vae = torch.optim.Adam(variational_ae.parameters(), lr=learning_rate_vae)\n",
    "criterion_vae = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; train loss: 0.9595501457943636; valid loss: 0.9483551383018494\n",
      "epoch 20; train loss: 0.9424716304330265; valid loss: 0.9371915221214294\n",
      "epoch 30; train loss: 0.9349792389308705; valid loss: 0.9275487065315247\n",
      "epoch 40; train loss: 0.924561412895427; valid loss: 0.917056941986084\n",
      "epoch 50; train loss: 0.9234924035913804; valid loss: 0.9217060804367065\n",
      "epoch 60; train loss: 0.9176436873043284; valid loss: 0.917456328868866\n",
      "epoch 70; train loss: 0.9151208786403432; valid loss: 0.9182617783546447\n",
      "epoch 80; train loss: 0.919321193414576; valid loss: 0.913764214515686\n",
      "epoch 90; train loss: 0.9164787530899048; valid loss: 0.9159284353256225\n",
      "epoch 100; train loss: 0.9129736283246208; valid loss: 0.9107045412063599\n",
      "epoch 110; train loss: 0.9155341141364154; valid loss: 0.9007219076156616\n",
      "epoch 120; train loss: 0.9065654277801514; valid loss: 0.8973768949508667\n",
      "epoch 130; train loss: 0.9177014862789827; valid loss: 0.9239564776420593\n",
      "epoch 140; train loss: 0.9182748864678776; valid loss: 0.918463158607483\n",
      "epoch 150; train loss: 0.9168830969754387; valid loss: 0.910295307636261\n",
      "epoch 160; train loss: 0.9139982076252208; valid loss: 0.9056699275970459\n",
      "epoch 170; train loss: 0.9094606112031376; valid loss: 0.904681670665741\n",
      "epoch 180; train loss: 0.9123589641907636; valid loss: 0.9161478996276855\n",
      "epoch 190; train loss: 0.9104082829811994; valid loss: 0.913395619392395\n",
      "epoch 200; train loss: 0.9135706775328692; valid loss: 0.9107055783271789\n"
     ]
    }
   ],
   "source": [
    "train_model_VAE(model=variational_ae, model_name='variational_autoencoder', optimizer=optimizer_vae, criterion=criterion_vae,\n",
    "                train_loader=train_dataloader_vae, val_loader=val_dataloader_vae, nr_of_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reconstruction Error</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>331.000000</td>\n",
       "      <td>331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.929822</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.967920</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.032932</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.105756</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.183746</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.372330</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>181.372162</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reconstruction Error  class\n",
       "count            331.000000  331.0\n",
       "mean               0.929822    0.0\n",
       "std                9.967920    0.0\n",
       "min                0.032932    0.0\n",
       "25%                0.105756    0.0\n",
       "50%                0.183746    0.0\n",
       "75%                0.372330    0.0\n",
       "max              181.372162    0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reconstruction Error</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18.280983</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>55.621185</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.121286</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.855274</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.633982</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.062162</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>410.286560</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reconstruction Error  class\n",
       "count            176.000000  176.0\n",
       "mean              18.280983    1.0\n",
       "std               55.621185    0.0\n",
       "min                0.121286    1.0\n",
       "25%                0.855274    1.0\n",
       "50%                2.633982    1.0\n",
       "75%                7.062162    1.0\n",
       "max              410.286560    1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df, test_MSEs = eval_on_testset(denoising_ae, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Model: variational_autoencoder, trying 40 thresholds from [0.1, 2.0]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "For more detail, call the function with `verbose=True`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimal_threshold_vae = try_threshold_grid(test_MSEs, y_test, 'variational_autoencoder', start=0.1, stop=2.0, num_thresholds=40, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Best Threshold 0.5384615384615384"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_7f957448_d563_11ec_a008_2016b948faac\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Inliers Accuracy</th>        <th class=\"col_heading level0 col1\" >Outliers Accuracy</th>        <th class=\"col_heading level0 col2\" >Overall Accuracy</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_7f957448_d563_11ec_a008_2016b948faacrow0_col0\" class=\"data row0 col0\" >0.839879</td>\n",
       "                        <td id=\"T_7f957448_d563_11ec_a008_2016b948faacrow0_col1\" class=\"data row0 col1\" >0.869318</td>\n",
       "                        <td id=\"T_7f957448_d563_11ec_a008_2016b948faacrow0_col2\" class=\"data row0 col2\" >0.850099</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b9549f9af0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Classification Report"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.84      0.88       331\n",
      "           1       0.74      0.87      0.80       176\n",
      "\n",
      "    accuracy                           0.85       507\n",
      "   macro avg       0.83      0.85      0.84       507\n",
      "weighted avg       0.86      0.85      0.85       507\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = classify_by_error(test_MSEs, optimal_threshold_vae)\n",
    "matrix = confusion_matrix(y_test, predictions)\n",
    "class_accuracies = matrix.diagonal()/matrix.sum(axis=1)\n",
    "acc_df = pd.DataFrame({\n",
    "    'Inliers Accuracy': [class_accuracies[0]], \n",
    "    'Outliers Accuracy': [class_accuracies[1]], \n",
    "    'Overall Accuracy': [accuracy_score(y_test, predictions)]\n",
    "})\n",
    "\n",
    "display(Markdown(f'### Best Threshold {optimal_threshold_vae}'))\n",
    "display(acc_df.style.hide_index())\n",
    "display(Markdown(f'##### Classification Report'))\n",
    "print(classification_report(y_test, predictions))\n",
    "plot_confusion_matrix(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have compared three different autoencoder architectures for outlier detection:\n",
    "1. undercomplete autoencoder\n",
    "2. denoising autoencoder\n",
    "3. variational autoencoder\n",
    "\n",
    "For each of them, I tuned the following hyperparameters:\n",
    "- learning rate\n",
    "- batch size\n",
    "- number of layers and their width (most importantly the size of the latent space)\n",
    "- threshold for reconstruction error\n",
    "\n",
    "I have chosen the best classifier based on the F1-score, where negative class is composed of inliers and positive class is composed of outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you can find the best hyper-parameters of the architectures. As for the layers, only encoder architecture is shown, since decoder contains the same layers reversed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Architecture Encoder</th>\n",
       "      <th>Latent Space Size</th>\n",
       "      <th>Reconstruction MSE Threshold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Architecture</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Undercomplete Autoencoder</th>\n",
       "      <td>0.01</td>\n",
       "      <td>64</td>\n",
       "      <td>Linear(21, 16) → ReLU → Linear(16, 14)</td>\n",
       "      <td>14</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Denoising Autoencoder</th>\n",
       "      <td>0.01</td>\n",
       "      <td>64</td>\n",
       "      <td>Linear(21, 16) → ReLU → Linear(16, 14)</td>\n",
       "      <td>14</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variational Autoencoder</th>\n",
       "      <td>0.01</td>\n",
       "      <td>64</td>\n",
       "      <td>Linear(21, 16) → ReLU → LinearMu(16, 14), Line...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Learning Rate  Batch Size  \\\n",
       "Architecture                                           \n",
       "Undercomplete Autoencoder           0.01          64   \n",
       "Denoising Autoencoder               0.01          64   \n",
       "Variational Autoencoder             0.01          64   \n",
       "\n",
       "                                                        Architecture Encoder  \\\n",
       "Architecture                                                                   \n",
       "Undercomplete Autoencoder             Linear(21, 16) → ReLU → Linear(16, 14)   \n",
       "Denoising Autoencoder                 Linear(21, 16) → ReLU → Linear(16, 14)   \n",
       "Variational Autoencoder    Linear(21, 16) → ReLU → LinearMu(16, 14), Line...   \n",
       "\n",
       "                           Latent Space Size  Reconstruction MSE Threshold  \n",
       "Architecture                                                                \n",
       "Undercomplete Autoencoder                 14                      0.538462  \n",
       "Denoising Autoencoder                     14                      0.538462  \n",
       "Variational Autoencoder                   14                      0.538462  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_df = pd.DataFrame({'Architecture': ['Undercomplete Autoencoder', 'Denoising Autoencoder', 'Variational Autoencoder'],\n",
    "                          'Learning Rate': [learning_rate_uae, learning_rate_dae, learning_rate_vae],\n",
    "                          'Batch Size': [64, 64, 64], \n",
    "                          'Architecture Encoder': [\n",
    "                              f'Linear({INPUT_SIZE}, {HIDDEN_SIZE_UAE}) → ReLU → Linear({HIDDEN_SIZE_UAE}, {LATENT_SIZE_UAE})', f'Linear({INPUT_SIZE}, {HIDDEN_SIZE_DAE}) → ReLU → Linear({HIDDEN_SIZE_DAE}, {LATENT_SIZE_DAE})', f'Linear({INPUT_SIZE}, {HIDDEN_SIZE_VAE}) → ReLU → LinearMu({HIDDEN_SIZE_VAE}, {LATENT_SIZE_VAE}), LinearSigma({HIDDEN_SIZE_VAE}, {LATENT_SIZE_VAE})'\n",
    "                          ],\n",
    "                          'Latent Space Size': [14, 14, 14],\n",
    "                          'Reconstruction MSE Threshold': [optimal_threshold_under, optimal_threshold_denoising, optimal_threshold_vae],\n",
    "                         })\n",
    "result_df = result_df.set_index('Architecture')\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bakalarka",
   "language": "python",
   "name": "bakalarka"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
