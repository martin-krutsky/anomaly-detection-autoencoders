{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Detection with Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\Anaconda3\\envs\\bakalarka\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\marti\\Anaconda3\\envs\\bakalarka\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\marti\\Anaconda3\\envs\\bakalarka\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import random\n",
    "from typing import Dict, List, Tuple, Type\n",
    "import warnings\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardio_dict = scipy.io.loadmat('cardio.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, written by Octave 3.8.0, 2014-12-18 10:48:09 UTC',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'X': array([[ 0.00491231,  0.69319077, -0.20364049, ...,  0.23149795,\n",
       "         -0.28978574, -0.49329397],\n",
       "        [ 0.11072935, -0.07990259, -0.20364049, ...,  0.09356344,\n",
       "         -0.25638541, -0.49329397],\n",
       "        [ 0.21654639, -0.27244466, -0.20364049, ...,  0.02459619,\n",
       "         -0.25638541,  1.14001753],\n",
       "        ...,\n",
       "        [-0.41835583, -0.91998844, -0.16463485, ..., -1.49268341,\n",
       "          0.24461959, -0.49329397],\n",
       "        [-0.41835583, -0.91998844, -0.15093411, ..., -1.42371616,\n",
       "          0.14441859, -0.49329397],\n",
       "        [-0.41835583, -0.91998844, -0.20364049, ..., -1.28578165,\n",
       "          3.58465295, -0.49329397]]),\n",
       " 'y': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardio_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cardio_dict['X']\n",
    "y = cardio_dict['y'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of input example: 21\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = X.shape[1]\n",
    "print(f'Size of input example: {INPUT_SIZE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the dataset into inliers and outliers:\n",
    "- only inliers are used for trainig the autoencoders\n",
    "- outliers are then mixed with the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inliers: 1655, Number of outliers: 176\n"
     ]
    }
   ],
   "source": [
    "X_inliers = X[y==0]\n",
    "y_inliers = np.zeros(len(X_inliers), dtype=int)\n",
    "X_outliers = X[y==1]\n",
    "y_outliers = np.ones(len(X_outliers), dtype=int)\n",
    "print(f'Number of inliers: {len(y_inliers)}, Number of outliers: {len(y_outliers)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the inliers into training, validation, and testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_inliers, y_inliers, test_size=0.20, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=1) # 0.2 x 0.8 = 0.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add outliers only to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.concatenate((X_test, X_outliers), axis=0)\n",
    "y_test = np.concatenate((y_test, y_outliers), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 1059 examples\n",
      "Validation set: 265 examples\n",
      "Testing set: 507 examples; inliers: 331, outliers: 176\n"
     ]
    }
   ],
   "source": [
    "print(f'Training set: {len(y_train)} examples')\n",
    "print(f'Validation set: {len(y_val)} examples')\n",
    "print(f'Testing set: {len(y_test)} examples; inliers: {np.sum(y_test==0)}, outliers: {np.sum(y_test==1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1059, 21)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataset and DataLoader instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardioDataset(Dataset):\n",
    "    def __init__(self, data: np.ndarray, labels: np.ndarray):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[np.ndarray, np.int32]:\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CardioDataset(X_train, y_train)\n",
    "val_data = CardioDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model: nn.Module, optimizer: torch.optim.Optimizer, criterion: nn.MSELoss, train_loader: DataLoader):\n",
    "    '''\n",
    "    Train one epoch of the model on training dataset batched by the train_loader.\n",
    "    \n",
    "    :param nn.Module model: model on which we perform one training epoch\n",
    "    :param torch.optim.Optimizer optimizer: optimizer, e.g. ADAM or SGD\n",
    "    :param nn.MSELoss criterion: loss function used for training\n",
    "    :param DataLoader train_loader: data object for batching training set\n",
    "    :returns: an average loss on the training dataset\n",
    "    '''\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, _ = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs.float(), inputs.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: nn.Module, model_name: str, optimizer: torch.optim.Optimizer, criterion: nn.MSELoss,\n",
    "                train_loader: DataLoader, val_loader: DataLoader, nr_of_epochs: int = 100, verbose: bool = True):\n",
    "    '''\n",
    "    Train the specified model, and evaluate on validation data.\n",
    "        \n",
    "    :param nn.Module model: model being trained\n",
    "    :param str model_name: model name, e.g. denoising_autoencoder\n",
    "    :param torch.optim.Optimizer optimizer: optimizer, e.g. ADAM or SGD\n",
    "    :param nn.MSELoss criterion: loss function used for training\n",
    "    :param DataLoader train_loader: data object for batching the training set\n",
    "    :param DataLoader val_loader: data object for batching the validation set\n",
    "    :param bool verbose: determining whether training and validation losses should be printed\n",
    "    :param int nr_of_epochs: number of training epochs\n",
    "    '''\n",
    "    best_loss = 10**12\n",
    "    best_model, model_path, best_epoch = None, None, None\n",
    "\n",
    "    for epoch in range(nr_of_epochs):\n",
    "        model.train()\n",
    "        train_loss = train_one_epoch(model, optimizer, criterion, train_loader)\n",
    "        model.eval()\n",
    "\n",
    "        # performance on validation set\n",
    "        valid_loss = 0.0\n",
    "        for i, data in enumerate(val_loader):\n",
    "            inputs, _ = data\n",
    "            outputs = model(inputs.float())\n",
    "            loss = criterion(outputs.float(), inputs.float())\n",
    "            valid_loss += loss.item()\n",
    "        valid_loss = valid_loss / len(val_loader)\n",
    "\n",
    "        # logging at each Nth epoch\n",
    "        if verbose and (epoch + 1) % 10 == 0:\n",
    "            print(f'epoch {epoch + 1}; train loss: {train_loss}; valid loss: {valid_loss}')\n",
    "        \n",
    "        # remember model with the best validation loss\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_model = model.state_dict()\n",
    "            best_epoch = epoch + 1\n",
    "\n",
    "    # save the overall best model - if verbose\n",
    "    if verbose:\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        os.makedirs('models/', exist_ok=True)\n",
    "        model_path = f'models/model_{model_name}_{timestamp}_epoch{best_epoch}'\n",
    "        torch.save(best_model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_testset(model: nn.Module, testset: np.ndarray, test_labels: np.ndarray, verbose: bool = True) -> Tuple[pd.DataFrame, np.ndarray]:\n",
    "    '''\n",
    "    Evaluate testing data on the model, calculate reconstruction error, print statistics on inliers and outliers\n",
    "        \n",
    "    :param nn.Module model: model being evaluated\n",
    "    :param np.ndarray testset: testing inputs\n",
    "    :param np.ndarray test_labels: ground-truth labels\n",
    "    :param bool verbose: determining whether reconstruction errors should be printed\n",
    "    :returns: dataframe with reconstruction errors and classes, reconstrution errors\n",
    "    '''\n",
    "    testset_tensor = torch.tensor(testset).float()\n",
    "    reconstructed_test = model(testset_tensor)\n",
    "    mse_test = torch.sum((reconstructed_test.detach() - testset_tensor) ** 2, axis=1)\n",
    "    error_df = pd.DataFrame({'Reconstruction Error': mse_test, 'class': y_test})\n",
    "    \n",
    "    if verbose:\n",
    "        display(error_df[error_df['class'] == 0].describe())\n",
    "        display(error_df[error_df['class'] == 1].describe())\n",
    "    return error_df, mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_by_error(MSEs: np.ndarray, thres: float) -> np.ndarray:\n",
    "    '''\n",
    "    Classify an array of reconstruction errors w.r.t. a threshold\n",
    "    \n",
    "    :param np.ndarray MSEs: mean squared reconstruction errors\n",
    "    :param float thres: threshold of reconstruction error between inliers and outliers\n",
    "    :returns: binary array of class ids; 0 = inlier, 1 = outlier\n",
    "    '''\n",
    "    return np.array(MSEs > thres, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confusion_mat: np.ndarray):\n",
    "    '''\n",
    "    Plot a confusion matrix of true vs predicted labels.\n",
    "    \n",
    "    :param np.ndarray confusion_mat: confusion matrix between true and predicted labels\n",
    "    '''\n",
    "    class_labels = ['Inlier', 'Outlier']\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(confusion_mat, xticklabels=class_labels, yticklabels=class_labels, annot=True, fmt=\"d\", annot_kws={\"size\": 14});\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.ylabel('True class')\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_threshold_grid(MSEs: np.ndarray, true_labels: np.ndarray, model_name: str, start: float = 0.0,\n",
    "                       stop: float = 5.0, num_thresholds: int = 10, verbose_lvl: int = 2) -> Tuple[float, float]:\n",
    "    '''\n",
    "    Plot a confusion matrix of true vs predicted labels.\n",
    "    \n",
    "    :param np.ndarray MSEs: mean squared reconstruction errors on testing set\n",
    "    :param np.ndarray true_labels: ground-truth labels\n",
    "    :param str model_name: model name, e.g. denoising_autoencoder\n",
    "    :param float start: start of threshold interval\n",
    "    :param float stop: end of threshold interval\n",
    "    :param int num_thresholds: number of thresholds tested in the interval\n",
    "    :param int verbose_lvl: level of verbosity - 0 = no verbosity, 2 = max verbosity\n",
    "    :returns: threshold with the highest anomaly f1-score, corresponding f1-score\n",
    "    '''\n",
    "    best_threshold = None\n",
    "    best_f1 = 0.0\n",
    "    if verbose_lvl >= 1:\n",
    "        display(Markdown(f'#### Model: {model_name}, trying {num_thresholds} thresholds from [{start}, {stop}]'))\n",
    "    if verbose_lvl == 1:\n",
    "        display(Markdown('For more detail, call the function with `verbose_lvl=2`'))\n",
    "        \n",
    "    for threshold in np.linspace(start, stop, num=num_thresholds):\n",
    "        predictions = classify_by_error(MSEs, threshold)\n",
    "        matrix = confusion_matrix(true_labels, predictions)\n",
    "        class_accuracies = matrix.diagonal()/matrix.sum(axis=1)\n",
    "        acc_df = pd.DataFrame({\n",
    "            'Inliers Accuracy': [class_accuracies[0]], \n",
    "            'Outliers Accuracy': [class_accuracies[1]], \n",
    "            'Overall Accuracy': [accuracy_score(true_labels, predictions)]\n",
    "        })\n",
    "        \n",
    "        outlier_f1 = f1_score(true_labels, predictions)\n",
    "        if outlier_f1 > best_f1:\n",
    "            best_f1 = outlier_f1\n",
    "            best_threshold = threshold\n",
    "        \n",
    "        if verbose_lvl >= 2:\n",
    "            display(Markdown(f'### Threshold {threshold}'))\n",
    "            display(acc_df.style.hide_index())\n",
    "            display(Markdown(f'##### Classification Report'))\n",
    "            print(classification_report(true_labels, predictions))\n",
    "            # plot_confusion_matrix(matrix)\n",
    "            display(Markdown('---'))\n",
    "    \n",
    "    return best_threshold, best_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypeparameter tuning functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a general tuning framework, I will try out (in a grid search) the following parameters for each of the architectures:\n",
    "- Batch size: 32, 64, 128\n",
    "- Learning rate: 1e-3, 1e-2\n",
    "- Hidden layer dimension: 16, 18\n",
    "- Latent space dimension: 10, 12, 14\n",
    "- Thresholds on reconstruction errors from interval [0.1; 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the number of layers and the architecture in general, I will try that by hand (calling the functions bellow multiple times)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting all random seeds for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = 123\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed: int = 123):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid-search functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_test_model(ModelClass: Type[nn.Module], hidden_size: int, latent_size: int, model_name: str, batch_size: int, learning_rate: float) -> Tuple[float, float]:\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, worker_init_fn=seed_worker, shuffle=False)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, worker_init_fn=seed_worker, shuffle=False)\n",
    "    \n",
    "    seed_all()\n",
    "    model = ModelClass(hidden_size, latent_size)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    train_model(model=model, model_name=model_name, optimizer=optimizer, criterion=criterion,\n",
    "                train_loader=train_loader, val_loader=val_loader, nr_of_epochs=200, verbose=False)\n",
    "    \n",
    "    df, MSEs = eval_on_testset(model, X_test, y_test, verbose=False)\n",
    "    threshold, f1 = try_threshold_grid(MSEs, y_test, model_name, start=0.1, stop=5.0, num_thresholds=50, verbose_lvl=0)\n",
    "    return threshold, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(ModelClass: Type[nn.Module], model_name: str, hidden_sizes: List[int], latent_sizes: List[int], batch_sizes: List[int], learning_rates: List[float]):\n",
    "    best_f1 = 0.0\n",
    "    best_model_params = None\n",
    "    \n",
    "    cartes_product = list(itertools.product(hidden_sizes, latent_sizes, batch_sizes, learning_rates))\n",
    "    for hidden_size, latent_size, batch_size, learning_rate in tqdm(cartes_product):\n",
    "        threshold, f1 = train_eval_test_model(ModelClass, hidden_size, latent_size, model_name, batch_size, learning_rate)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_model_params = hidden_size, latent_size, batch_size, learning_rate, threshold\n",
    "    return best_model_params, best_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Undercomplete AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UndercompleteAutoEncoder(nn.Module):\n",
    "    def __init__(self, hidden_size: int, latent_size: int):\n",
    "        super(UndercompleteAutoEncoder, self).__init__()\n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Linear(INPUT_SIZE, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, latent_size),\n",
    "        )\n",
    "        self.decode = nn.Sequential(\n",
    "            nn.Linear(latent_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, INPUT_SIZE),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.encode(x)\n",
    "        x = self.decode(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried this architecture either with two or three layers. The two-layer architecture performed better, probably due to the fact that bigger autoencoders are prone to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [04:18<00:00,  7.19s/it]\n"
     ]
    }
   ],
   "source": [
    "best_model_params_uae, best_f1_uae = grid_search(ModelClass=UndercompleteAutoEncoder,\n",
    "                                                 model_name='undercomplete_autoencoder',\n",
    "                                                 hidden_sizes=[16, 18],\n",
    "                                                 latent_sizes=[10, 12, 14],\n",
    "                                                 batch_sizes=[32, 64, 128], \n",
    "                                                 learning_rates=[1e-3, 1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Best Parameters"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_1ba36f3d_d576_11ec_8359_2016b948faac\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Hidden Size</th>        <th class=\"col_heading level0 col1\" >Latent Size</th>        <th class=\"col_heading level0 col2\" >Batch Size</th>        <th class=\"col_heading level0 col3\" >Learning Rate</th>        <th class=\"col_heading level0 col4\" >Threshold</th>        <th class=\"col_heading level0 col5\" >F1 Score</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_1ba36f3d_d576_11ec_8359_2016b948faacrow0_col0\" class=\"data row0 col0\" >16</td>\n",
       "                        <td id=\"T_1ba36f3d_d576_11ec_8359_2016b948faacrow0_col1\" class=\"data row0 col1\" >14</td>\n",
       "                        <td id=\"T_1ba36f3d_d576_11ec_8359_2016b948faacrow0_col2\" class=\"data row0 col2\" >32</td>\n",
       "                        <td id=\"T_1ba36f3d_d576_11ec_8359_2016b948faacrow0_col3\" class=\"data row0 col3\" >0.010000</td>\n",
       "                        <td id=\"T_1ba36f3d_d576_11ec_8359_2016b948faacrow0_col4\" class=\"data row0 col4\" >0.900000</td>\n",
       "                        <td id=\"T_1ba36f3d_d576_11ec_8359_2016b948faacrow0_col5\" class=\"data row0 col5\" >0.855491</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22fff7a3340>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params_df_uae = pd.DataFrame([list(best_model_params_uae) + [best_f1_uae]], columns=['Hidden Size', 'Latent Size', 'Batch Size', 'Learning Rate', 'Threshold', 'F1 Score'])\n",
    "display(Markdown('#### Best Parameters'))\n",
    "display(best_params_df_uae.style.hide_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I run again the model with the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_uae = best_model_params_uae[2]\n",
    "hidden_size_uae = best_model_params_uae[0]\n",
    "latent_size_uae = best_model_params_uae[1]\n",
    "learning_rate_uae = best_model_params_uae[3]\n",
    "\n",
    "train_dataloader_uae = DataLoader(train_data, batch_size=batch_size_uae, worker_init_fn=seed_worker, shuffle=False)\n",
    "val_dataloader_uae = DataLoader(val_data, batch_size=batch_size_uae, worker_init_fn=seed_worker, shuffle=False)\n",
    "\n",
    "seed_all()\n",
    "undercomplete_ae = UndercompleteAutoEncoder(hidden_size=hidden_size_uae, latent_size=latent_size_uae)\n",
    "\n",
    "optimizer_uae = torch.optim.Adam(undercomplete_ae.parameters(), lr=learning_rate_uae)\n",
    "criterion_uae = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; train loss: 0.07845563222380246; valid loss: 0.06856349938445622\n",
      "epoch 20; train loss: 0.04769162340637516; valid loss: 0.04086662973794672\n",
      "epoch 30; train loss: 0.04048974625766277; valid loss: 0.037478564514054194\n",
      "epoch 40; train loss: 0.025916583945646006; valid loss: 0.027021025203996234\n",
      "epoch 50; train loss: 0.017154373584643882; valid loss: 0.01997534434000651\n",
      "epoch 60; train loss: 0.017489522366839295; valid loss: 0.019071616439355746\n",
      "epoch 70; train loss: 0.01733766498920672; valid loss: 0.018864728096458647\n",
      "epoch 80; train loss: 0.015525188023114906; valid loss: 0.01962609847800599\n",
      "epoch 90; train loss: 0.01612220926429419; valid loss: 0.01988972889052497\n",
      "epoch 100; train loss: 0.016747563776067075; valid loss: 0.020137556932038732\n",
      "epoch 110; train loss: 0.014342290047994432; valid loss: 0.01636328051487605\n",
      "epoch 120; train loss: 0.01566670821322238; valid loss: 0.01898117767026027\n",
      "epoch 130; train loss: 0.011706831221304396; valid loss: 0.01514923500104083\n",
      "epoch 140; train loss: 0.010908141663736281; valid loss: 0.013287417435397705\n",
      "epoch 150; train loss: 0.015142141279819258; valid loss: 0.017097757508357365\n",
      "epoch 160; train loss: 0.008616338196374914; valid loss: 0.010937473840183683\n",
      "epoch 170; train loss: 0.018314020653419635; valid loss: 0.015691071852213807\n",
      "epoch 180; train loss: 0.01029823935481117; valid loss: 0.013863063934776518\n",
      "epoch 190; train loss: 0.011962159495691167; valid loss: 0.014752012056608995\n",
      "epoch 200; train loss: 0.012855915626620544; valid loss: 0.017641963126758736\n"
     ]
    }
   ],
   "source": [
    "train_model(model=undercomplete_ae, model_name='undercomplete_autoencoder', optimizer=optimizer_uae, criterion=criterion_uae,\n",
    "            train_loader=train_dataloader_uae, val_loader=val_dataloader_uae, nr_of_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reconstruction Error</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>331.000000</td>\n",
       "      <td>331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.997535</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.095651</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.035125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.137133</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.229582</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.365493</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>201.888657</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reconstruction Error  class\n",
       "count            331.000000  331.0\n",
       "mean               0.997535    0.0\n",
       "std               11.095651    0.0\n",
       "min                0.035125    0.0\n",
       "25%                0.137133    0.0\n",
       "50%                0.229582    0.0\n",
       "75%                0.365493    0.0\n",
       "max              201.888657    0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reconstruction Error</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.597584</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>61.017159</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.157307</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.379958</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.555787</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.013056</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>460.212860</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reconstruction Error  class\n",
       "count            176.000000  176.0\n",
       "mean              17.597584    1.0\n",
       "std               61.017159    0.0\n",
       "min                0.157307    1.0\n",
       "25%                1.379958    1.0\n",
       "50%                2.555787    1.0\n",
       "75%                6.013056    1.0\n",
       "max              460.212860    1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df, test_MSEs = eval_on_testset(undercomplete_ae, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Model: undercomplete_autoencoder, trying 50 thresholds from [0.1, 5.0]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "For more detail, call the function with `verbose_lvl=2`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimal_threshold_under, optimal_f1_under = try_threshold_grid(test_MSEs, y_test, 'undercomplete_autoencoder', start=0.1, stop=5.0, num_thresholds=50, verbose_lvl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Best Threshold 0.90, F1 Score 0.86"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_3d7947d8_d576_11ec_8359_2016b948faac\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Inliers Accuracy</th>        <th class=\"col_heading level0 col1\" >Outliers Accuracy</th>        <th class=\"col_heading level0 col2\" >Overall Accuracy</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_3d7947d8_d576_11ec_8359_2016b948faacrow0_col0\" class=\"data row0 col0\" >0.933535</td>\n",
       "                        <td id=\"T_3d7947d8_d576_11ec_8359_2016b948faacrow0_col1\" class=\"data row0 col1\" >0.840909</td>\n",
       "                        <td id=\"T_3d7947d8_d576_11ec_8359_2016b948faacrow0_col2\" class=\"data row0 col2\" >0.901381</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22f83a45490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Classification Report"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93       331\n",
      "           1       0.87      0.84      0.86       176\n",
      "\n",
      "    accuracy                           0.90       507\n",
      "   macro avg       0.89      0.89      0.89       507\n",
      "weighted avg       0.90      0.90      0.90       507\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = classify_by_error(test_MSEs, optimal_threshold_under)\n",
    "matrix = confusion_matrix(y_test, predictions)\n",
    "class_accuracies = matrix.diagonal()/matrix.sum(axis=1)\n",
    "acc_df = pd.DataFrame({\n",
    "    'Inliers Accuracy': [class_accuracies[0]], \n",
    "    'Outliers Accuracy': [class_accuracies[1]], \n",
    "    'Overall Accuracy': [accuracy_score(y_test, predictions)]\n",
    "})\n",
    "\n",
    "display(Markdown(f'#### Best Threshold {optimal_threshold_under:.2f}, F1 Score {optimal_f1_under:.2f}'))\n",
    "display(acc_df.style.hide_index())\n",
    "display(Markdown(f'##### Classification Report'))\n",
    "print(classification_report(y_test, predictions))\n",
    "plot_confusion_matrix(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Denoising AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingAutoEncoder(nn.Module):\n",
    "    def __init__(self, hidden_size: int, latent_size: int, noise_rate: float = 0.1):\n",
    "        super(DenoisingAutoEncoder, self).__init__()\n",
    "        self.noise_rate = noise_rate\n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Linear(INPUT_SIZE, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, latent_size),\n",
    "        )\n",
    "        self.decode = nn.Sequential(\n",
    "            nn.Linear(latent_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, INPUT_SIZE),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.training:\n",
    "            # randn_like returns tensor the same shape as x with random numbers\n",
    "            # from a normal distribution with mean 0 and variance 1\n",
    "            x = x + torch.randn_like(x) * self.noise_rate\n",
    "        x = self.encode(x)\n",
    "        x = self.decode(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [04:29<00:00,  7.48s/it]\n"
     ]
    }
   ],
   "source": [
    "best_model_params_dae, best_f1_dae = grid_search(ModelClass=DenoisingAutoEncoder,\n",
    "                                                 model_name='denoising_autoencoder',\n",
    "                                                 hidden_sizes=[16, 18],\n",
    "                                                 latent_sizes=[10, 12, 14],\n",
    "                                                 batch_sizes=[32, 64, 128], \n",
    "                                                 learning_rates=[1e-3, 1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Best Parameters"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_01af36b2_d577_11ec_8359_2016b948faac\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Hidden Size</th>        <th class=\"col_heading level0 col1\" >Latent Size</th>        <th class=\"col_heading level0 col2\" >Batch Size</th>        <th class=\"col_heading level0 col3\" >Learning Rate</th>        <th class=\"col_heading level0 col4\" >Threshold</th>        <th class=\"col_heading level0 col5\" >F1 Score</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_01af36b2_d577_11ec_8359_2016b948faacrow0_col0\" class=\"data row0 col0\" >16</td>\n",
       "                        <td id=\"T_01af36b2_d577_11ec_8359_2016b948faacrow0_col1\" class=\"data row0 col1\" >12</td>\n",
       "                        <td id=\"T_01af36b2_d577_11ec_8359_2016b948faacrow0_col2\" class=\"data row0 col2\" >128</td>\n",
       "                        <td id=\"T_01af36b2_d577_11ec_8359_2016b948faacrow0_col3\" class=\"data row0 col3\" >0.001000</td>\n",
       "                        <td id=\"T_01af36b2_d577_11ec_8359_2016b948faacrow0_col4\" class=\"data row0 col4\" >2.500000</td>\n",
       "                        <td id=\"T_01af36b2_d577_11ec_8359_2016b948faacrow0_col5\" class=\"data row0 col5\" >0.846797</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22f84815880>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params_df_dae = pd.DataFrame([list(best_model_params_dae) + [best_f1_dae]], columns=['Hidden Size', 'Latent Size', 'Batch Size', 'Learning Rate', 'Threshold', 'F1 Score'])\n",
    "display(Markdown('#### Best Parameters'))\n",
    "display(best_params_df_dae.style.hide_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I run again the model with the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_dae = best_model_params_dae[2]\n",
    "hidden_size_dae = best_model_params_dae[0]\n",
    "latent_size_dae = best_model_params_dae[1]\n",
    "learning_rate_dae = best_model_params_dae[3]\n",
    "\n",
    "train_dataloader_dae = DataLoader(train_data, batch_size=batch_size_dae, worker_init_fn=seed_worker, shuffle=False)\n",
    "val_dataloader_dae = DataLoader(val_data, batch_size=batch_size_dae, worker_init_fn=seed_worker, shuffle=False)\n",
    "\n",
    "seed_all()\n",
    "denoising_ae = DenoisingAutoEncoder(hidden_size=hidden_size_dae, latent_size=latent_size_dae)\n",
    "\n",
    "optimizer_dae = torch.optim.Adam(denoising_ae.parameters(), lr=learning_rate_dae)\n",
    "criterion_dae = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; train loss: 0.6273554364840189; valid loss: 0.6077722112337748\n",
      "epoch 20; train loss: 0.35867228441768223; valid loss: 0.3350010911623637\n",
      "epoch 30; train loss: 0.2742500834994846; valid loss: 0.24429390827814737\n",
      "epoch 40; train loss: 0.23053580522537231; valid loss: 0.20139877001444498\n",
      "epoch 50; train loss: 0.17496129870414734; valid loss: 0.15229076147079468\n",
      "epoch 60; train loss: 0.1410075897971789; valid loss: 0.11917980015277863\n",
      "epoch 70; train loss: 0.12402068823575974; valid loss: 0.10059588650862376\n",
      "epoch 80; train loss: 0.11600607881943385; valid loss: 0.09177618970473607\n",
      "epoch 90; train loss: 0.11042225940359963; valid loss: 0.08552430445949237\n",
      "epoch 100; train loss: 0.1060052944554223; valid loss: 0.08078381543358167\n",
      "epoch 110; train loss: 0.10101216038068135; valid loss: 0.07591464494665463\n",
      "epoch 120; train loss: 0.09499162104394701; valid loss: 0.07032812138398488\n",
      "epoch 130; train loss: 0.08655848022964266; valid loss: 0.06319066757957141\n",
      "epoch 140; train loss: 0.08184898396333058; valid loss: 0.05898443112770716\n",
      "epoch 150; train loss: 0.07894435028235118; valid loss: 0.056217665473620095\n",
      "epoch 160; train loss: 0.07591650469435586; valid loss: 0.05406152829527855\n",
      "epoch 170; train loss: 0.07231129043632084; valid loss: 0.05137588083744049\n",
      "epoch 180; train loss: 0.06774173180262248; valid loss: 0.047991023088494934\n",
      "epoch 190; train loss: 0.0620950311422348; valid loss: 0.044119490310549736\n",
      "epoch 200; train loss: 0.057841844028896756; valid loss: 0.04105243335167567\n"
     ]
    }
   ],
   "source": [
    "train_model(model=denoising_ae, model_name='denoising_autoencoder', optimizer=optimizer_dae, criterion=criterion_dae,\n",
    "            train_loader=train_dataloader_dae, val_loader=val_dataloader_dae, nr_of_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reconstruction Error</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>331.000000</td>\n",
       "      <td>331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.734478</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.510483</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.061012</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.367438</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.681380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.355170</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>190.269714</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reconstruction Error  class\n",
       "count            331.000000  331.0\n",
       "mean               1.734478    0.0\n",
       "std               10.510483    0.0\n",
       "min                0.061012    0.0\n",
       "25%                0.367438    0.0\n",
       "50%                0.681380    0.0\n",
       "75%                1.355170    0.0\n",
       "max              190.269714    0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reconstruction Error</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24.047546</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>59.326084</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.265362</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.668185</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.091310</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.906005</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>450.141785</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reconstruction Error  class\n",
       "count            176.000000  176.0\n",
       "mean              24.047546    1.0\n",
       "std               59.326084    0.0\n",
       "min                0.265362    1.0\n",
       "25%                3.668185    1.0\n",
       "50%                7.091310    1.0\n",
       "75%               18.906005    1.0\n",
       "max              450.141785    1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df, test_MSEs = eval_on_testset(denoising_ae, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Model: denoising_autoencoder, trying 50 thresholds from [0.1, 5.0]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "For more detail, call the function with `verbose_lvl=2`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimal_threshold_denoising, optimal_f1_denoising = try_threshold_grid(test_MSEs, y_test, 'denoising_autoencoder', start=0.1, stop=5.0, num_thresholds=50, verbose_lvl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Best Threshold 2.50, F1 Score 0.85"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_109743fe_d577_11ec_9121_2016b948faac\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Inliers Accuracy</th>        <th class=\"col_heading level0 col1\" >Outliers Accuracy</th>        <th class=\"col_heading level0 col2\" >Overall Accuracy</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_109743fe_d577_11ec_9121_2016b948faacrow0_col0\" class=\"data row0 col0\" >0.906344</td>\n",
       "                        <td id=\"T_109743fe_d577_11ec_9121_2016b948faacrow0_col1\" class=\"data row0 col1\" >0.863636</td>\n",
       "                        <td id=\"T_109743fe_d577_11ec_9121_2016b948faacrow0_col2\" class=\"data row0 col2\" >0.891519</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22f84815580>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Classification Report"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       331\n",
      "           1       0.83      0.86      0.85       176\n",
      "\n",
      "    accuracy                           0.89       507\n",
      "   macro avg       0.88      0.88      0.88       507\n",
      "weighted avg       0.89      0.89      0.89       507\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = classify_by_error(test_MSEs, optimal_threshold_denoising)\n",
    "matrix = confusion_matrix(y_test, predictions)\n",
    "class_accuracies = matrix.diagonal()/matrix.sum(axis=1)\n",
    "acc_df = pd.DataFrame({\n",
    "    'Inliers Accuracy': [class_accuracies[0]], \n",
    "    'Outliers Accuracy': [class_accuracies[1]], \n",
    "    'Overall Accuracy': [accuracy_score(y_test, predictions)]\n",
    "})\n",
    "\n",
    "display(Markdown(f'#### Best Threshold {optimal_threshold_denoising:.2f}, F1 Score {optimal_f1_denoising:.2f}'))\n",
    "display(acc_df.style.hide_index())\n",
    "display(Markdown(f'##### Classification Report'))\n",
    "print(classification_report(y_test, predictions))\n",
    "plot_confusion_matrix(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Variational AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Altered training and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch_VAE(model: nn.Module, optimizer: torch.optim.Optimizer, criterion: nn.MSELoss, train_loader: DataLoader):\n",
    "    '''\n",
    "    Train one epoch of the model on training dataset batched by the train_loader.\n",
    "    \n",
    "    :param nn.Module model: model on which we perform one training epoch\n",
    "    :param torch.optim.Optimizer optimizer: optimizer, e.g. ADAM or SGD\n",
    "    :param nn.MSELoss criterion: loss function used for training\n",
    "    :param DataLoader train_loader: data object for batching training set\n",
    "    :returns: an average loss on the training dataset\n",
    "    '''\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, _ = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs.float())\n",
    "        loss = ((outputs.float() - inputs.float()) ** 2).mean() + model.kl\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_VAE(model: nn.Module, model_name: str, optimizer: torch.optim.Optimizer, criterion: nn.MSELoss, \n",
    "                    train_loader: DataLoader, val_loader: DataLoader, nr_of_epochs: int = 100):\n",
    "    '''\n",
    "    Train the specified model, and evaluate on validation data.\n",
    "        \n",
    "    :param nn.Module model: model being trained\n",
    "    :param str model_name: model name, e.g. denoising_autoencoder\n",
    "    :param torch.optim.Optimizer optimizer: optimizer, e.g. ADAM or SGD\n",
    "    :param nn.MSELoss criterion: loss function used for training\n",
    "    :param DataLoader train_loader: data object for batching the training set\n",
    "    :param DataLoader val_loader: data object for batching the validation set\n",
    "    :param int nr_of_epochs: number of training epochs\n",
    "    '''\n",
    "    best_loss = 10**12\n",
    "    best_model, model_path, best_epoch = None, None, None\n",
    "\n",
    "    for epoch in range(nr_of_epochs):\n",
    "        model.train()\n",
    "        train_loss = train_one_epoch_VAE(model, optimizer, criterion, train_loader)\n",
    "        model.eval()\n",
    "\n",
    "        # performance on validation set\n",
    "        with torch.no_grad():\n",
    "            valid_loss = 0.0\n",
    "            for i, data in enumerate(val_loader):\n",
    "                inputs, _ = data\n",
    "                outputs = model(inputs.float())\n",
    "                loss = ((outputs.float() - inputs.float()) ** 2).mean() + model.kl\n",
    "                valid_loss += loss.item()\n",
    "            valid_loss = valid_loss / len(val_loader)\n",
    "\n",
    "            # logging at each Nth epoch\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f'epoch {epoch + 1}; train loss: {train_loss}; valid loss: {valid_loss}')\n",
    "\n",
    "            # remember model with the best validation loss\n",
    "            if valid_loss < best_loss:\n",
    "                best_loss = valid_loss\n",
    "                best_model = model.state_dict()\n",
    "                best_epoch = epoch + 1\n",
    "\n",
    "    # save the overall best model\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    os.makedirs('models/', exist_ok=True)\n",
    "    model_path = f'models/model_{model_name}_{timestamp}_epoch{best_epoch}'\n",
    "    torch.save(best_model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_testset_VAE(model: nn.Module, testset: np.ndarray, test_labels: np.ndarray) -> Tuple[pd.DataFrame, np.ndarray]:\n",
    "    '''\n",
    "    Evaluate testing data on the model, calculate reconstruction error, print statistics on inliers and outliers\n",
    "        \n",
    "    :param nn.Module model: model being evaluated\n",
    "    :param np.ndarray testset: testing inputs\n",
    "    :param np.ndarray test_labels: ground-truth labels\n",
    "    :returns: dataframe with reconstruction errors and classes, reconstrution errors\n",
    "    '''\n",
    "    testset_tensor = torch.tensor(testset).float()\n",
    "    reconstructed_test = model(testset_tensor)\n",
    "    mse_test = torch.mean((reconstructed_test.detach() - testset_tensor) ** 2, axis=1) + model.kl\n",
    "    error_df = pd.DataFrame({'Reconstruction Error': mse_test, 'class': y_test})\n",
    "    \n",
    "    display(error_df[error_df['class'] == 0].describe())\n",
    "    display(error_df[error_df['class'] == 1].describe())\n",
    "    return error_df, mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self, hidden_size: int, latent_size: int):\n",
    "        super(VariationalAutoEncoder, self).__init__()\n",
    "        self.encLin1 = nn.Linear(INPUT_SIZE, hidden_size)\n",
    "        self.reluEnc = nn.ReLU()\n",
    "        self.encLin21 = nn.Linear(hidden_size, latent_size)\n",
    "        self.encLin22 = nn.Linear(hidden_size, latent_size)\n",
    "        self.normal = torch.distributions.Normal(0, 1)\n",
    "        self.kl = 0\n",
    "        \n",
    "        self.decLin1 = nn.Linear(latent_size, hidden_size)\n",
    "        self.reluDec = nn.ReLU()\n",
    "        self.decLin2 = nn.Linear(hidden_size, INPUT_SIZE)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.reluEnc(self.encLin1(x))\n",
    "        mu = self.encLin21(x)\n",
    "        sigma = torch.exp(self.encLin22(x))\n",
    "        z = mu + sigma * self.normal.sample(mu.shape)\n",
    "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).mean()\n",
    "\n",
    "        x = self.reluDec(self.decLin1(z))\n",
    "        x = self.decLin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [05:38<00:00,  9.39s/it]\n"
     ]
    }
   ],
   "source": [
    "best_model_params_vae, best_f1_vae = grid_search(ModelClass=VariationalAutoEncoder,\n",
    "                                                 model_name='variational_autoencoder',\n",
    "                                                 hidden_sizes=[16, 18],\n",
    "                                                 latent_sizes=[10, 12, 14],\n",
    "                                                 batch_sizes=[32, 64, 128], \n",
    "                                                 learning_rates=[1e-3, 1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Best Parameters"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_02d50867_d578_11ec_8359_2016b948faac\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Hidden Size</th>        <th class=\"col_heading level0 col1\" >Latent Size</th>        <th class=\"col_heading level0 col2\" >Batch Size</th>        <th class=\"col_heading level0 col3\" >Learning Rate</th>        <th class=\"col_heading level0 col4\" >Threshold</th>        <th class=\"col_heading level0 col5\" >F1 Score</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_02d50867_d578_11ec_8359_2016b948faacrow0_col0\" class=\"data row0 col0\" >18</td>\n",
       "                        <td id=\"T_02d50867_d578_11ec_8359_2016b948faacrow0_col1\" class=\"data row0 col1\" >14</td>\n",
       "                        <td id=\"T_02d50867_d578_11ec_8359_2016b948faacrow0_col2\" class=\"data row0 col2\" >32</td>\n",
       "                        <td id=\"T_02d50867_d578_11ec_8359_2016b948faacrow0_col3\" class=\"data row0 col3\" >0.010000</td>\n",
       "                        <td id=\"T_02d50867_d578_11ec_8359_2016b948faacrow0_col4\" class=\"data row0 col4\" >0.800000</td>\n",
       "                        <td id=\"T_02d50867_d578_11ec_8359_2016b948faacrow0_col5\" class=\"data row0 col5\" >0.854651</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22f84450ac0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params_df_vae = pd.DataFrame([list(best_model_params_vae) + [best_f1_vae]], columns=['Hidden Size', 'Latent Size', 'Batch Size', 'Learning Rate', 'Threshold', 'F1 Score'])\n",
    "display(Markdown('#### Best Parameters'))\n",
    "display(best_params_df_vae.style.hide_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I run again the model with the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_vae = best_model_params_vae[2]\n",
    "hidden_size_vae = best_model_params_vae[0]\n",
    "latent_size_vae = best_model_params_vae[1]\n",
    "learning_rate_vae = best_model_params_vae[3]\n",
    "\n",
    "train_dataloader_vae = DataLoader(train_data, batch_size=batch_size_vae, worker_init_fn=seed_worker, shuffle=False)\n",
    "val_dataloader_vae = DataLoader(val_data, batch_size=batch_size_vae, worker_init_fn=seed_worker, shuffle=False)\n",
    "\n",
    "seed_all()\n",
    "variational_ae = VariationalAutoEncoder(hidden_size=hidden_size_vae, latent_size=latent_size_vae)\n",
    "\n",
    "optimizer_vae = torch.optim.Adam(variational_ae.parameters(), lr=learning_rate_vae)\n",
    "criterion_vae = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; train loss: 0.9655616984647863; valid loss: 0.9452367424964905\n",
      "epoch 20; train loss: 0.9612430789891411; valid loss: 0.9340046511756049\n",
      "epoch 30; train loss: 0.9342184277141795; valid loss: 0.9196026192771064\n",
      "epoch 40; train loss: 0.9166464069310356; valid loss: 0.9140909711519877\n",
      "epoch 50; train loss: 0.9231396054520327; valid loss: 0.9115574161211649\n",
      "epoch 60; train loss: 0.9090644208823934; valid loss: 0.9203195836808946\n",
      "epoch 70; train loss: 0.9171910864465377; valid loss: 0.9246436887317233\n",
      "epoch 80; train loss: 0.9091035110108993; valid loss: 0.9260574513011508\n",
      "epoch 90; train loss: 0.9162524097106036; valid loss: 0.9062003162172105\n",
      "epoch 100; train loss: 0.9171900433652541; valid loss: 0.9053299691942003\n",
      "epoch 110; train loss: 0.9079202238251182; valid loss: 0.897371855047014\n",
      "epoch 120; train loss: 0.9031243587241453; valid loss: 0.8979257610109117\n",
      "epoch 130; train loss: 0.9102316972087411; valid loss: 0.9061709973547194\n",
      "epoch 140; train loss: 0.9086198701578028; valid loss: 0.9327506356769137\n",
      "epoch 150; train loss: 0.9133458593312431; valid loss: 0.9122739566697015\n",
      "epoch 160; train loss: 0.9071790225365582; valid loss: 0.9184758265813192\n",
      "epoch 170; train loss: 0.9049752477337333; valid loss: 0.9001974662144979\n",
      "epoch 180; train loss: 0.9018716864726123; valid loss: 0.900566471947564\n",
      "epoch 190; train loss: 0.899522965445238; valid loss: 0.9027135570844015\n",
      "epoch 200; train loss: 0.899614320081823; valid loss: 0.9142403933737013\n"
     ]
    }
   ],
   "source": [
    "train_model_VAE(model=variational_ae, model_name='variational_autoencoder', optimizer=optimizer_vae, criterion=criterion_vae,\n",
    "                train_loader=train_dataloader_vae, val_loader=val_dataloader_vae, nr_of_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reconstruction Error</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>331.000000</td>\n",
       "      <td>331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.734478</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.510483</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.061012</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.367438</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.681380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.355170</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>190.269714</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reconstruction Error  class\n",
       "count            331.000000  331.0\n",
       "mean               1.734478    0.0\n",
       "std               10.510483    0.0\n",
       "min                0.061012    0.0\n",
       "25%                0.367438    0.0\n",
       "50%                0.681380    0.0\n",
       "75%                1.355170    0.0\n",
       "max              190.269714    0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reconstruction Error</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24.047546</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>59.326084</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.265362</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.668185</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.091310</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.906005</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>450.141785</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reconstruction Error  class\n",
       "count            176.000000  176.0\n",
       "mean              24.047546    1.0\n",
       "std               59.326084    0.0\n",
       "min                0.265362    1.0\n",
       "25%                3.668185    1.0\n",
       "50%                7.091310    1.0\n",
       "75%               18.906005    1.0\n",
       "max              450.141785    1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df, test_MSEs = eval_on_testset(denoising_ae, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Model: variational_autoencoder, trying 50 thresholds from [0.1, 5.0]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "For more detail, call the function with `verbose_lvl=2`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimal_threshold_vae, optimal_f1_vae = try_threshold_grid(test_MSEs, y_test, 'variational_autoencoder', start=0.1, stop=5.0, num_thresholds=50, verbose_lvl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Best Threshold 2.50, F1 Score 0.85"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_2b51c130_d578_11ec_9121_2016b948faac\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Inliers Accuracy</th>        <th class=\"col_heading level0 col1\" >Outliers Accuracy</th>        <th class=\"col_heading level0 col2\" >Overall Accuracy</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_2b51c130_d578_11ec_9121_2016b948faacrow0_col0\" class=\"data row0 col0\" >0.906344</td>\n",
       "                        <td id=\"T_2b51c130_d578_11ec_9121_2016b948faacrow0_col1\" class=\"data row0 col1\" >0.863636</td>\n",
       "                        <td id=\"T_2b51c130_d578_11ec_9121_2016b948faacrow0_col2\" class=\"data row0 col2\" >0.891519</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22f83e03b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Classification Report"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       331\n",
      "           1       0.83      0.86      0.85       176\n",
      "\n",
      "    accuracy                           0.89       507\n",
      "   macro avg       0.88      0.88      0.88       507\n",
      "weighted avg       0.89      0.89      0.89       507\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = classify_by_error(test_MSEs, optimal_threshold_vae)\n",
    "matrix = confusion_matrix(y_test, predictions)\n",
    "class_accuracies = matrix.diagonal()/matrix.sum(axis=1)\n",
    "acc_df = pd.DataFrame({\n",
    "    'Inliers Accuracy': [class_accuracies[0]], \n",
    "    'Outliers Accuracy': [class_accuracies[1]], \n",
    "    'Overall Accuracy': [accuracy_score(y_test, predictions)]\n",
    "})\n",
    "\n",
    "display(Markdown(f'#### Best Threshold {optimal_threshold_vae:.2f}, F1 Score {optimal_f1_vae:.2f}'))\n",
    "display(acc_df.style.hide_index())\n",
    "display(Markdown(f'##### Classification Report'))\n",
    "print(classification_report(y_test, predictions))\n",
    "plot_confusion_matrix(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have compared three different autoencoder architectures for outlier detection:\n",
    "1. undercomplete autoencoder\n",
    "2. denoising autoencoder\n",
    "3. variational autoencoder\n",
    "\n",
    "For each of them, I tuned the following hyperparameters in a grid search:\n",
    "- Batch size\n",
    "- Learning rate\n",
    "- Hidden layer dimension\n",
    "- Latent space dimension\n",
    "- Thresholds on reconstruction errors from interval\n",
    "\n",
    "Moreover, for each architecture, I tried adding another hidden layer to the encoder and the decoder manually (for each option, I ran the gridsearch), and chose the better architecture.\n",
    "\n",
    "I have chosen the best classifier based on the F1-score, where negative class is composed of inliers and positive class is composed of outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you can find the best hyper-parameters of the architectures. As for the layers, only encoder architecture is shown, since decoder contains almost the same layers, just reversed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Architecture Encoder</th>\n",
       "      <th>Latent Space Size</th>\n",
       "      <th>MSE Threshold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Architecture</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Undercomplete Autoencoder</th>\n",
       "      <td>0.855491</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>Linear(21, 16) → ReLU → Linear(16, 14)</td>\n",
       "      <td>14</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Denoising Autoencoder</th>\n",
       "      <td>0.846797</td>\n",
       "      <td>0.001</td>\n",
       "      <td>128</td>\n",
       "      <td>Linear(21, 16) → ReLU → Linear(16, 12)</td>\n",
       "      <td>12</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variational Autoencoder</th>\n",
       "      <td>0.846797</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>Linear(21, 18) → ReLU → Mu(18, 14)/Sigma(18, 14)</td>\n",
       "      <td>14</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           F1 Score  Learning Rate  Batch Size  \\\n",
       "Architecture                                                     \n",
       "Undercomplete Autoencoder  0.855491          0.010          32   \n",
       "Denoising Autoencoder      0.846797          0.001         128   \n",
       "Variational Autoencoder    0.846797          0.010          32   \n",
       "\n",
       "                                                       Architecture Encoder  \\\n",
       "Architecture                                                                  \n",
       "Undercomplete Autoencoder            Linear(21, 16) → ReLU → Linear(16, 14)   \n",
       "Denoising Autoencoder                Linear(21, 16) → ReLU → Linear(16, 12)   \n",
       "Variational Autoencoder    Linear(21, 18) → ReLU → Mu(18, 14)/Sigma(18, 14)   \n",
       "\n",
       "                           Latent Space Size  MSE Threshold  \n",
       "Architecture                                                 \n",
       "Undercomplete Autoencoder                 14            0.9  \n",
       "Denoising Autoencoder                     12            2.5  \n",
       "Variational Autoencoder                   14            2.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_df = pd.DataFrame({'Architecture': ['Undercomplete Autoencoder', 'Denoising Autoencoder', 'Variational Autoencoder'],\n",
    "                          'F1 Score': [optimal_f1_under, optimal_f1_denoising, optimal_f1_vae],\n",
    "                          'Learning Rate': [learning_rate_uae, learning_rate_dae, learning_rate_vae],\n",
    "                          'Batch Size': [batch_size_uae, batch_size_dae, batch_size_vae], \n",
    "                          'Architecture Encoder': [\n",
    "                              f'Linear({INPUT_SIZE}, {hidden_size_uae}) → ReLU → Linear({hidden_size_uae}, {latent_size_uae})', f'Linear({INPUT_SIZE}, {hidden_size_dae}) → ReLU → Linear({hidden_size_dae}, {latent_size_dae})', f'Linear({INPUT_SIZE}, {hidden_size_vae}) → ReLU → Mu({hidden_size_vae}, {latent_size_vae})/Sigma({hidden_size_vae}, {latent_size_vae})'\n",
    "                          ],\n",
    "                          'Latent Space Size': [latent_size_uae, latent_size_dae, latent_size_vae],\n",
    "                          'MSE Threshold': [optimal_threshold_under, optimal_threshold_denoising, optimal_threshold_vae],\n",
    "                         })\n",
    "result_df = result_df.set_index('Architecture')\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bakalarka",
   "language": "python",
   "name": "bakalarka"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
