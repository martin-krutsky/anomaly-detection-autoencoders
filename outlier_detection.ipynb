{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Detection with Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\Anaconda3\\envs\\bakalarka\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\marti\\Anaconda3\\envs\\bakalarka\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\marti\\Anaconda3\\envs\\bakalarka\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import random\n",
    "from typing import Dict, List, Tuple, Type\n",
    "import warnings\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardio_dict = scipy.io.loadmat('cardio.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, written by Octave 3.8.0, 2014-12-18 10:48:09 UTC',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'X': array([[ 0.00491231,  0.69319077, -0.20364049, ...,  0.23149795,\n",
       "         -0.28978574, -0.49329397],\n",
       "        [ 0.11072935, -0.07990259, -0.20364049, ...,  0.09356344,\n",
       "         -0.25638541, -0.49329397],\n",
       "        [ 0.21654639, -0.27244466, -0.20364049, ...,  0.02459619,\n",
       "         -0.25638541,  1.14001753],\n",
       "        ...,\n",
       "        [-0.41835583, -0.91998844, -0.16463485, ..., -1.49268341,\n",
       "          0.24461959, -0.49329397],\n",
       "        [-0.41835583, -0.91998844, -0.15093411, ..., -1.42371616,\n",
       "          0.14441859, -0.49329397],\n",
       "        [-0.41835583, -0.91998844, -0.20364049, ..., -1.28578165,\n",
       "          3.58465295, -0.49329397]]),\n",
       " 'y': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardio_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cardio_dict['X']\n",
    "y = cardio_dict['y'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of input example: 21\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = X.shape[1]\n",
    "print(f'Size of input example: {INPUT_SIZE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the dataset into inliers and outliers:\n",
    "- only inliers are used for trainig the autoencoders\n",
    "- outliers are then mixed with the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inliers: 1655, Number of outliers: 176\n"
     ]
    }
   ],
   "source": [
    "X_inliers = X[y==0]\n",
    "y_inliers = np.zeros(len(X_inliers), dtype=int)\n",
    "X_outliers = X[y==1]\n",
    "y_outliers = np.ones(len(X_outliers), dtype=int)\n",
    "print(f'Number of inliers: {len(y_inliers)}, Number of outliers: {len(y_outliers)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the inliers into training, validation, and testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_inliers, y_inliers, test_size=0.20, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=1) # 0.2 x 0.8 = 0.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add outliers only to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.concatenate((X_test, X_outliers), axis=0)\n",
    "y_test = np.concatenate((y_test, y_outliers), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 1059 examples\n",
      "Validation set: 265 examples\n",
      "Testing set: 507 examples; inliers: 331, outliers: 176\n"
     ]
    }
   ],
   "source": [
    "print(f'Training set: {len(y_train)} examples')\n",
    "print(f'Validation set: {len(y_val)} examples')\n",
    "print(f'Testing set: {len(y_test)} examples; inliers: {np.sum(y_test==0)}, outliers: {np.sum(y_test==1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1059, 21)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataset and DataLoader instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardioDataset(Dataset):\n",
    "    def __init__(self, data: np.ndarray, labels: np.ndarray):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[np.ndarray, np.int32]:\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CardioDataset(X_train, y_train)\n",
    "val_data = CardioDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model: nn.Module, optimizer: torch.optim.Optimizer, criterion: nn.MSELoss, train_loader: DataLoader):\n",
    "    '''\n",
    "    Train one epoch of the model on training dataset batched by the train_loader.\n",
    "    \n",
    "    :param nn.Module model: model on which we perform one training epoch\n",
    "    :param torch.optim.Optimizer optimizer: optimizer, e.g. ADAM or SGD\n",
    "    :param nn.MSELoss criterion: loss function used for training\n",
    "    :param DataLoader train_loader: data object for batching training set\n",
    "    :returns: an average loss on the training dataset\n",
    "    '''\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, _ = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs.float(), inputs.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: nn.Module, model_name: str, optimizer: torch.optim.Optimizer, criterion: nn.MSELoss,\n",
    "                train_loader: DataLoader, val_loader: DataLoader, nr_of_epochs: int = 100, verbose: bool = True):\n",
    "    '''\n",
    "    Train the specified model, and evaluate on validation data.\n",
    "        \n",
    "    :param nn.Module model: model being trained\n",
    "    :param str model_name: model name, e.g. denoising_autoencoder\n",
    "    :param torch.optim.Optimizer optimizer: optimizer, e.g. ADAM or SGD\n",
    "    :param nn.MSELoss criterion: loss function used for training\n",
    "    :param DataLoader train_loader: data object for batching the training set\n",
    "    :param DataLoader val_loader: data object for batching the validation set\n",
    "    :param int nr_of_epochs: number of training epochs\n",
    "    :param bool verbose: determining whether training and validation losses should be printed\n",
    "    '''\n",
    "    best_loss = 10**12\n",
    "    best_model, model_path, best_epoch = None, None, None\n",
    "\n",
    "    for epoch in range(nr_of_epochs):\n",
    "        model.train()\n",
    "        train_loss = train_one_epoch(model, optimizer, criterion, train_loader)\n",
    "        model.eval()\n",
    "\n",
    "        # performance on validation set\n",
    "        valid_loss = 0.0\n",
    "        for i, data in enumerate(val_loader):\n",
    "            inputs, _ = data\n",
    "            outputs = model(inputs.float())\n",
    "            loss = criterion(outputs.float(), inputs.float())\n",
    "            valid_loss += loss.item()\n",
    "        valid_loss = valid_loss / len(val_loader)\n",
    "\n",
    "        # logging at each Nth epoch\n",
    "        if verbose and (epoch + 1) % 20 == 0:\n",
    "            print(f'epoch {epoch + 1}; train loss: {train_loss}; valid loss: {valid_loss}')\n",
    "        \n",
    "        # remember model with the best validation loss\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_model = model.state_dict()\n",
    "            best_epoch = epoch + 1\n",
    "\n",
    "    # save the overall best model - if verbose\n",
    "    if verbose:\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        os.makedirs('models/', exist_ok=True)\n",
    "        model_path = f'models/model_{model_name}_{timestamp}_epoch{best_epoch}'\n",
    "        torch.save(best_model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_testset(model: nn.Module, testset: np.ndarray, test_labels: np.ndarray, verbose: bool = True) -> Tuple[pd.DataFrame, np.ndarray]:\n",
    "    '''\n",
    "    Evaluate testing data on the model, calculate reconstruction error, print statistics on inliers and outliers\n",
    "        \n",
    "    :param nn.Module model: model being evaluated\n",
    "    :param np.ndarray testset: testing inputs\n",
    "    :param np.ndarray test_labels: ground-truth labels\n",
    "    :param bool verbose: determining whether reconstruction errors should be printed\n",
    "    :returns: dataframe with reconstruction errors and classes, reconstrution errors\n",
    "    '''\n",
    "    testset_tensor = torch.tensor(testset).float()\n",
    "    reconstructed_test = model(testset_tensor)\n",
    "    mse_test = torch.sum((reconstructed_test.detach() - testset_tensor) ** 2, axis=1)\n",
    "    error_df = pd.DataFrame({'Reconstruction Error': mse_test, 'class': y_test})\n",
    "    \n",
    "    if verbose:\n",
    "        display(error_df[error_df['class'] == 0].describe())\n",
    "        display(error_df[error_df['class'] == 1].describe())\n",
    "    return error_df, mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_by_error(MSEs: np.ndarray, thres: float) -> np.ndarray:\n",
    "    '''\n",
    "    Classify an array of reconstruction errors w.r.t. a threshold\n",
    "    \n",
    "    :param np.ndarray MSEs: mean squared reconstruction errors\n",
    "    :param float thres: threshold of reconstruction error between inliers and outliers\n",
    "    :returns: binary array of class ids; 0 = inlier, 1 = outlier\n",
    "    '''\n",
    "    return np.array(MSEs > thres, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confusion_mat: np.ndarray):\n",
    "    '''\n",
    "    Plot a confusion matrix of true vs predicted labels.\n",
    "    \n",
    "    :param np.ndarray confusion_mat: confusion matrix between true and predicted labels\n",
    "    '''\n",
    "    class_labels = ['Inlier', 'Outlier']\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(confusion_mat, xticklabels=class_labels, yticklabels=class_labels, annot=True, fmt=\"d\", annot_kws={\"size\": 14});\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.ylabel('True class')\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_threshold_grid(MSEs: np.ndarray, true_labels: np.ndarray, model_name: str, start: float = 0.0,\n",
    "                       stop: float = 5.0, num_thresholds: int = 10, verbose_lvl: int = 2) -> Tuple[float, float]:\n",
    "    '''\n",
    "    Plot a confusion matrix of true vs predicted labels.\n",
    "    \n",
    "    :param np.ndarray MSEs: mean squared reconstruction errors on testing set\n",
    "    :param np.ndarray true_labels: ground-truth labels\n",
    "    :param str model_name: model name, e.g. denoising_autoencoder\n",
    "    :param float start: start of threshold interval\n",
    "    :param float stop: end of threshold interval\n",
    "    :param int num_thresholds: number of thresholds tested in the interval\n",
    "    :param int verbose_lvl: level of verbosity - 0 = no verbosity, 2 = max verbosity\n",
    "    :returns: threshold with the highest anomaly f1-score, corresponding f1-score\n",
    "    '''\n",
    "    best_threshold = None\n",
    "    best_f1 = 0.0\n",
    "    if verbose_lvl >= 1:\n",
    "        display(Markdown(f'#### Model: {model_name}, trying {num_thresholds} thresholds from [{start}, {stop}]'))\n",
    "    if verbose_lvl == 1:\n",
    "        display(Markdown('For more detail, call the function with `verbose_lvl=2`'))\n",
    "        \n",
    "    for threshold in np.linspace(start, stop, num=num_thresholds):\n",
    "        predictions = classify_by_error(MSEs, threshold)\n",
    "        matrix = confusion_matrix(true_labels, predictions)\n",
    "        class_accuracies = matrix.diagonal()/matrix.sum(axis=1)\n",
    "        acc_df = pd.DataFrame({\n",
    "            'Inliers Accuracy': [class_accuracies[0]], \n",
    "            'Outliers Accuracy': [class_accuracies[1]], \n",
    "            'Overall Accuracy': [accuracy_score(true_labels, predictions)]\n",
    "        })\n",
    "        \n",
    "        outlier_f1 = f1_score(true_labels, predictions)\n",
    "        if outlier_f1 > best_f1:\n",
    "            best_f1 = outlier_f1\n",
    "            best_threshold = threshold\n",
    "        \n",
    "        if verbose_lvl >= 2:\n",
    "            display(Markdown(f'### Threshold {threshold}'))\n",
    "            display(acc_df.style.hide_index())\n",
    "            display(Markdown(f'##### Classification Report'))\n",
    "            print(classification_report(true_labels, predictions))\n",
    "            # plot_confusion_matrix(matrix)\n",
    "            display(Markdown('---'))\n",
    "    \n",
    "    return best_threshold, best_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypeparameter tuning functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a general tuning framework, I will try out (in a grid search) the following parameters for each of the architectures:\n",
    "- Batch size: 32; 64; 128\n",
    "- Learning rate: 1e-3; 1e-2\n",
    "- Hidden layer count and dimension: 16; 18; two hidden layers [18, 16]\n",
    "- Latent space dimension: 10; 12; 14\n",
    "- 50 thresholds on reconstruction errors from interval [0.1; 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting all random seeds for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id: int):\n",
    "    '''\n",
    "    Set random seed for DataLoader initialization\n",
    "    \n",
    "    :param int worker_id: id given by DataLoader\n",
    "    '''\n",
    "    worker_seed = 123\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed: int = 123):\n",
    "    '''\n",
    "    Set random seeds (all of them) for PyTorch training and eval loop\n",
    "    \n",
    "    :param int seed: random seed\n",
    "    '''\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid-search functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_test_model(ModelClass: Type[nn.Module], hidden_sizes: List[int], latent_size: int, model_name: str,\n",
    "                          batch_size: int, learning_rate: float, seed: int) -> Tuple[float, float]:\n",
    "    '''\n",
    "    Train and evaluate model with concrete hyperparameters, try threshold grid.\n",
    "    \n",
    "    :param Type[nn.Module] ModelClass: class of model to be trained\n",
    "    :param List[int] hidden_sizes: list determining number of hidden layers and their sizes\n",
    "    :param int latent_size: size of the latent space\n",
    "    :param str model_name: name of the model architecture\n",
    "    :param int batch_size: batch size for training and validation\n",
    "    :param float learning_rate: learning rate for the optimizer\n",
    "    :param int seed: random seed for PyTorch\n",
    "    :returns: best MSE threshold, best F1 score\n",
    "    '''\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, worker_init_fn=seed_worker, shuffle=False)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, worker_init_fn=seed_worker, shuffle=False)\n",
    "    \n",
    "    seed_all(seed)\n",
    "    model = ModelClass(hidden_sizes, latent_size)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    train_model(model=model, model_name=model_name, optimizer=optimizer, criterion=criterion,\n",
    "                train_loader=train_loader, val_loader=val_loader, nr_of_epochs=200, verbose=False)\n",
    "    \n",
    "    df, MSEs = eval_on_testset(model, X_test, y_test, verbose=False)\n",
    "    threshold, f1 = try_threshold_grid(MSEs, y_test, model_name, start=0.1, stop=5.0, num_thresholds=50, verbose_lvl=0)\n",
    "    return threshold, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(ModelClass: Type[nn.Module], model_name: str, hidden_sizes_ls: List[List[int]], latent_sizes: List[int],\n",
    "                batch_sizes: List[int], learning_rates: List[float], seeds: List[int]):\n",
    "    '''\n",
    "    Try out grid of hyperparameters constructed as a cartesian product of the given values, \n",
    "    return the best parameters according to the model's F1 score.\n",
    "    \n",
    "    :param Type[nn.Module] ModelClass: class of model to be trained\n",
    "    :param str model_name: name of the model architecture\n",
    "    :param List[List[int]] hidden_sizes_ls: list of lists determining number of hidden layers and their sizes\n",
    "    :param List[int] latent_sizes: sizes of the latent space\n",
    "    :param List[int] batch_sizes: batch sizes for training and validation\n",
    "    :param List[float] learning_rates: learning rates for the optimizer\n",
    "    :param List[int] seeds: random seeds for PyTorch\n",
    "    :returns: best hyperparameters, best F1 score\n",
    "    '''\n",
    "    best_f1 = 0.0\n",
    "    best_model_params = None\n",
    "    \n",
    "    cartes_product = list(itertools.product(hidden_sizes_ls, latent_sizes, batch_sizes, learning_rates, seeds))\n",
    "    for hidden_sizes, latent_size, batch_size, learning_rate, seed in tqdm(cartes_product):\n",
    "        threshold, f1 = train_eval_test_model(ModelClass, hidden_sizes, latent_size, model_name, batch_size, learning_rate, seed)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_model_params = hidden_sizes, latent_size, batch_size, learning_rate, seed, threshold\n",
    "    return best_model_params, best_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Undercomplete AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UndercompleteAutoEncoder(nn.Module):\n",
    "    def __init__(self, hidden_sizes: List[int], latent_size: int):\n",
    "        super(UndercompleteAutoEncoder, self).__init__()\n",
    "        \n",
    "        encode_layers = [nn.Linear(INPUT_SIZE, hidden_sizes[0]), nn.ReLU()]\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "            encode_layers += [nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.ReLU()]\n",
    "        encode_layers += [nn.Linear(hidden_sizes[-1], latent_size)]\n",
    "        self.encode = nn.Sequential(*encode_layers)\n",
    "        \n",
    "        decode_layers = [nn.Linear(latent_size, hidden_sizes[-1]), nn.ReLU()]\n",
    "        for i in range(1, len(hidden_sizes)):\n",
    "            decode_layers += [nn.Linear(hidden_sizes[-i], hidden_sizes[-i-1]), nn.ReLU()]\n",
    "        decode_layers += [nn.Linear(hidden_sizes[0], INPUT_SIZE)]\n",
    "        self.decode = nn.Sequential(*decode_layers)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.encode(x)\n",
    "        x = self.decode(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 108/108 [15:00<00:00,  8.34s/it]\n"
     ]
    }
   ],
   "source": [
    "best_model_params_uae, best_f1_uae = grid_search(ModelClass=UndercompleteAutoEncoder,\n",
    "                                                 model_name='undercomplete_autoencoder',\n",
    "                                                 hidden_sizes_ls=[[16], [18], [18, 16]],\n",
    "                                                 latent_sizes=[12, 14],\n",
    "                                                 batch_sizes=[32, 64, 128], \n",
    "                                                 learning_rates=[1e-3, 1e-2], \n",
    "                                                 seeds=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Best Parameters"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_dc044925_d5cc_11ec_bd2f_2016b948faac\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Hidden Size</th>        <th class=\"col_heading level0 col1\" >Latent Size</th>        <th class=\"col_heading level0 col2\" >Batch Size</th>        <th class=\"col_heading level0 col3\" >Learning Rate</th>        <th class=\"col_heading level0 col4\" >Seed</th>        <th class=\"col_heading level0 col5\" >Threshold</th>        <th class=\"col_heading level0 col6\" >F1 Score</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_dc044925_d5cc_11ec_bd2f_2016b948faacrow0_col0\" class=\"data row0 col0\" >[18]</td>\n",
       "                        <td id=\"T_dc044925_d5cc_11ec_bd2f_2016b948faacrow0_col1\" class=\"data row0 col1\" >14</td>\n",
       "                        <td id=\"T_dc044925_d5cc_11ec_bd2f_2016b948faacrow0_col2\" class=\"data row0 col2\" >32</td>\n",
       "                        <td id=\"T_dc044925_d5cc_11ec_bd2f_2016b948faacrow0_col3\" class=\"data row0 col3\" >0.010000</td>\n",
       "                        <td id=\"T_dc044925_d5cc_11ec_bd2f_2016b948faacrow0_col4\" class=\"data row0 col4\" >1</td>\n",
       "                        <td id=\"T_dc044925_d5cc_11ec_bd2f_2016b948faacrow0_col5\" class=\"data row0 col5\" >0.600000</td>\n",
       "                        <td id=\"T_dc044925_d5cc_11ec_bd2f_2016b948faacrow0_col6\" class=\"data row0 col6\" >0.853868</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ef3ceb5550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params_df_uae = pd.DataFrame([list(best_model_params_uae) + [best_f1_uae]], columns=['Hidden Sizes', 'Latent Size', 'Batch Size', 'Learning Rate', 'Seed', 'Threshold', 'F1 Score'])\n",
    "display(Markdown('#### Best Parameters'))\n",
    "display(best_params_df_uae.style.hide_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I run again the model with the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_uae = best_model_params_uae[2]\n",
    "hidden_sizes_uae = best_model_params_uae[0]\n",
    "latent_size_uae = best_model_params_uae[1]\n",
    "learning_rate_uae = best_model_params_uae[3]\n",
    "seed_uae = best_model_params_uae[4]\n",
    "\n",
    "train_dataloader_uae = DataLoader(train_data, batch_size=batch_size_uae, worker_init_fn=seed_worker, shuffle=False)\n",
    "val_dataloader_uae = DataLoader(val_data, batch_size=batch_size_uae, worker_init_fn=seed_worker, shuffle=False)\n",
    "\n",
    "seed_all(seed_uae)\n",
    "undercomplete_ae = UndercompleteAutoEncoder(hidden_sizes=hidden_sizes_uae, latent_size=latent_size_uae)\n",
    "\n",
    "optimizer_uae = torch.optim.Adam(undercomplete_ae.parameters(), lr=learning_rate_uae)\n",
    "criterion_uae = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; train loss: 0.03723937683903119; valid loss: 0.03797032290862666\n",
      "epoch 40; train loss: 0.020090154070845422; valid loss: 0.02357626251048512\n",
      "epoch 60; train loss: 0.015453275320503642; valid loss: 0.01929182093590498\n",
      "epoch 80; train loss: 0.015264093136305319; valid loss: 0.02071880352579885\n",
      "epoch 100; train loss: 0.012497355147977085; valid loss: 0.016371890488598082\n",
      "epoch 120; train loss: 0.01673270616789951; valid loss: 0.02242951084756189\n",
      "epoch 140; train loss: 0.012553147519664729; valid loss: 0.015977088051537674\n",
      "epoch 160; train loss: 0.011872202651027371; valid loss: 0.016514806904726557\n",
      "epoch 180; train loss: 0.011415168478646699; valid loss: 0.015309110076891052\n",
      "epoch 200; train loss: 0.009998493444393663; valid loss: 0.01199456418140067\n"
     ]
    }
   ],
   "source": [
    "train_model(model=undercomplete_ae, model_name='undercomplete_autoencoder', optimizer=optimizer_uae, criterion=criterion_uae,\n",
    "            train_loader=train_dataloader_uae, val_loader=val_dataloader_uae, nr_of_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reconstruction Error</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>331.000000</td>\n",
       "      <td>331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.917306</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.461358</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.031810</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.097631</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.151630</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.288254</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>208.562317</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reconstruction Error  class\n",
       "count            331.000000  331.0\n",
       "mean               0.917306    0.0\n",
       "std               11.461358    0.0\n",
       "min                0.031810    0.0\n",
       "25%                0.097631    0.0\n",
       "50%                0.151630    0.0\n",
       "75%                0.288254    0.0\n",
       "max              208.562317    0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reconstruction Error</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.228100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>65.033806</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.096019</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.921840</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.642808</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.661962</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>486.885803</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reconstruction Error  class\n",
       "count            176.000000  176.0\n",
       "mean              16.228100    1.0\n",
       "std               65.033806    0.0\n",
       "min                0.096019    1.0\n",
       "25%                0.921840    1.0\n",
       "50%                1.642808    1.0\n",
       "75%                4.661962    1.0\n",
       "max              486.885803    1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df, test_MSEs = eval_on_testset(undercomplete_ae, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Model: undercomplete_autoencoder, trying 50 thresholds from [0.1, 5.0]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "For more detail, call the function with `verbose_lvl=2`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimal_threshold_under, optimal_f1_under = try_threshold_grid(test_MSEs, y_test, 'undercomplete_autoencoder', start=0.1, stop=5.0, num_thresholds=50, verbose_lvl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Best Threshold 0.60, F1 Score 0.85"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_e2b3f61e_d5cc_11ec_8899_2016b948faac\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Inliers Accuracy</th>        <th class=\"col_heading level0 col1\" >Outliers Accuracy</th>        <th class=\"col_heading level0 col2\" >Overall Accuracy</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_e2b3f61e_d5cc_11ec_8899_2016b948faacrow0_col0\" class=\"data row0 col0\" >0.927492</td>\n",
       "                        <td id=\"T_e2b3f61e_d5cc_11ec_8899_2016b948faacrow0_col1\" class=\"data row0 col1\" >0.846591</td>\n",
       "                        <td id=\"T_e2b3f61e_d5cc_11ec_8899_2016b948faacrow0_col2\" class=\"data row0 col2\" >0.899408</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ef3d2edeb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Classification Report"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92       331\n",
      "           1       0.86      0.85      0.85       176\n",
      "\n",
      "    accuracy                           0.90       507\n",
      "   macro avg       0.89      0.89      0.89       507\n",
      "weighted avg       0.90      0.90      0.90       507\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = classify_by_error(test_MSEs, optimal_threshold_under)\n",
    "matrix = confusion_matrix(y_test, predictions)\n",
    "class_accuracies = matrix.diagonal()/matrix.sum(axis=1)\n",
    "acc_df = pd.DataFrame({\n",
    "    'Inliers Accuracy': [class_accuracies[0]], \n",
    "    'Outliers Accuracy': [class_accuracies[1]], \n",
    "    'Overall Accuracy': [accuracy_score(y_test, predictions)]\n",
    "})\n",
    "\n",
    "display(Markdown(f'#### Best Threshold {optimal_threshold_under:.2f}, F1 Score {optimal_f1_under:.2f}'))\n",
    "display(acc_df.style.hide_index())\n",
    "display(Markdown(f'##### Classification Report'))\n",
    "print(classification_report(y_test, predictions))\n",
    "plot_confusion_matrix(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Denoising AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an aditional hyperparameter in the denoising autoencoder - noise rate. I have chosen its value 0.1 experimentally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingAutoEncoder(nn.Module):\n",
    "    def __init__(self, hidden_sizes: List[int], latent_size: int, noise_rate: float = 0.1):\n",
    "        super(DenoisingAutoEncoder, self).__init__()\n",
    "        self.noise_rate = noise_rate\n",
    "        \n",
    "        encode_layers = [nn.Linear(INPUT_SIZE, hidden_sizes[0]), nn.ReLU()]\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "            encode_layers += [nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.ReLU()]\n",
    "        encode_layers += [nn.Linear(hidden_sizes[-1], latent_size)]\n",
    "        self.encode = nn.Sequential(*encode_layers)\n",
    "        \n",
    "        decode_layers = [nn.Linear(latent_size, hidden_sizes[-1]), nn.ReLU()]\n",
    "        for i in range(1, len(hidden_sizes)):\n",
    "            decode_layers += [nn.Linear(hidden_sizes[-i], hidden_sizes[-i-1]), nn.ReLU()]\n",
    "        decode_layers += [nn.Linear(hidden_sizes[0], INPUT_SIZE)]\n",
    "        self.decode = nn.Sequential(*decode_layers)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.training:\n",
    "            # randn_like returns tensor the same shape as x with random numbers\n",
    "            # from a normal distribution with mean 0 and variance 1\n",
    "            x = x + torch.randn_like(x) * self.noise_rate\n",
    "        x = self.encode(x)\n",
    "        x = self.decode(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 108/108 [14:32<00:00,  8.08s/it]\n"
     ]
    }
   ],
   "source": [
    "best_model_params_dae, best_f1_dae = grid_search(ModelClass=DenoisingAutoEncoder,\n",
    "                                                 model_name='denoising_autoencoder',\n",
    "                                                 hidden_sizes_ls=[[16], [18], [18, 16]],\n",
    "                                                 latent_sizes=[12, 14],\n",
    "                                                 batch_sizes=[32, 64, 128], \n",
    "                                                 learning_rates=[1e-3, 1e-2], \n",
    "                                                 seeds=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Best Parameters"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_254640d1_d5cf_11ec_bd2f_2016b948faac\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Hidden Sizes</th>        <th class=\"col_heading level0 col1\" >Latent Size</th>        <th class=\"col_heading level0 col2\" >Batch Size</th>        <th class=\"col_heading level0 col3\" >Learning Rate</th>        <th class=\"col_heading level0 col4\" >Seed</th>        <th class=\"col_heading level0 col5\" >Threshold</th>        <th class=\"col_heading level0 col6\" >F1 Score</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_254640d1_d5cf_11ec_bd2f_2016b948faacrow0_col0\" class=\"data row0 col0\" >[18, 16]</td>\n",
       "                        <td id=\"T_254640d1_d5cf_11ec_bd2f_2016b948faacrow0_col1\" class=\"data row0 col1\" >12</td>\n",
       "                        <td id=\"T_254640d1_d5cf_11ec_bd2f_2016b948faacrow0_col2\" class=\"data row0 col2\" >64</td>\n",
       "                        <td id=\"T_254640d1_d5cf_11ec_bd2f_2016b948faacrow0_col3\" class=\"data row0 col3\" >0.001000</td>\n",
       "                        <td id=\"T_254640d1_d5cf_11ec_bd2f_2016b948faacrow0_col4\" class=\"data row0 col4\" >0</td>\n",
       "                        <td id=\"T_254640d1_d5cf_11ec_bd2f_2016b948faacrow0_col5\" class=\"data row0 col5\" >4.600000</td>\n",
       "                        <td id=\"T_254640d1_d5cf_11ec_bd2f_2016b948faacrow0_col6\" class=\"data row0 col6\" >0.857955</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ef3f6be220>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params_df_dae = pd.DataFrame([list(best_model_params_dae) + [best_f1_dae]], columns=['Hidden Sizes', 'Latent Size', 'Batch Size', 'Learning Rate', 'Seed', 'Threshold', 'F1 Score'])\n",
    "display(Markdown('#### Best Parameters'))\n",
    "display(best_params_df_dae.style.hide_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I run again the model with the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_dae = best_model_params_dae[2]\n",
    "hidden_sizes_dae = best_model_params_dae[0]\n",
    "latent_size_dae = best_model_params_dae[1]\n",
    "learning_rate_dae = best_model_params_dae[3]\n",
    "seed_dae = best_model_params_dae[4]\n",
    "\n",
    "train_dataloader_dae = DataLoader(train_data, batch_size=batch_size_dae, worker_init_fn=seed_worker, shuffle=False)\n",
    "val_dataloader_dae = DataLoader(val_data, batch_size=batch_size_dae, worker_init_fn=seed_worker, shuffle=False)\n",
    "\n",
    "seed_all(seed_dae)\n",
    "denoising_ae = DenoisingAutoEncoder(hidden_sizes=hidden_sizes_dae, latent_size=latent_size_dae)\n",
    "\n",
    "optimizer_dae = torch.optim.Adam(denoising_ae.parameters(), lr=learning_rate_dae)\n",
    "criterion_dae = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; train loss: 0.2810297652202494; valid loss: 0.262992861866951\n",
      "epoch 40; train loss: 0.21063781573491938; valid loss: 0.20053890645503997\n",
      "epoch 60; train loss: 0.17799240175415487; valid loss: 0.167845618724823\n",
      "epoch 80; train loss: 0.13241556505946553; valid loss: 0.1142901137471199\n",
      "epoch 100; train loss: 0.10906535299385295; valid loss: 0.08841354250907899\n",
      "epoch 120; train loss: 0.10111656828838236; valid loss: 0.08080225810408592\n",
      "epoch 140; train loss: 0.09485143598388224; valid loss: 0.07402787953615189\n",
      "epoch 160; train loss: 0.08643094800850924; valid loss: 0.06698484793305397\n",
      "epoch 180; train loss: 0.08066995726788745; valid loss: 0.0638043113052845\n",
      "epoch 200; train loss: 0.07677312765051336; valid loss: 0.06005171090364456\n"
     ]
    }
   ],
   "source": [
    "train_model(model=denoising_ae, model_name='denoising_autoencoder', optimizer=optimizer_dae, criterion=criterion_dae,\n",
    "            train_loader=train_dataloader_dae, val_loader=val_dataloader_dae, nr_of_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reconstruction Error</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>331.000000</td>\n",
       "      <td>331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.252344</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.951236</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.102357</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.564487</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.996288</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.972276</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>197.650070</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reconstruction Error  class\n",
       "count            331.000000  331.0\n",
       "mean               2.252344    0.0\n",
       "std               10.951236    0.0\n",
       "min                0.102357    0.0\n",
       "25%                0.564487    0.0\n",
       "50%                0.996288    0.0\n",
       "75%                1.972276    0.0\n",
       "max              197.650070    0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reconstruction Error</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26.376417</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>55.906544</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.332025</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.609365</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.143871</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.133160</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>426.904022</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reconstruction Error  class\n",
       "count            176.000000  176.0\n",
       "mean              26.376417    1.0\n",
       "std               55.906544    0.0\n",
       "min                0.332025    1.0\n",
       "25%                5.609365    1.0\n",
       "50%               10.143871    1.0\n",
       "75%               22.133160    1.0\n",
       "max              426.904022    1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df, test_MSEs = eval_on_testset(denoising_ae, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Model: denoising_autoencoder, trying 50 thresholds from [0.1, 5.0]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "For more detail, call the function with `verbose_lvl=2`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimal_threshold_denoising, optimal_f1_denoising = try_threshold_grid(test_MSEs, y_test, 'denoising_autoencoder', start=0.1, stop=5.0, num_thresholds=50, verbose_lvl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Best Threshold 4.60, F1 Score 0.86"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_2fe634be_d5cf_11ec_b60b_2016b948faac\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Inliers Accuracy</th>        <th class=\"col_heading level0 col1\" >Outliers Accuracy</th>        <th class=\"col_heading level0 col2\" >Overall Accuracy</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_2fe634be_d5cf_11ec_b60b_2016b948faacrow0_col0\" class=\"data row0 col0\" >0.924471</td>\n",
       "                        <td id=\"T_2fe634be_d5cf_11ec_b60b_2016b948faacrow0_col1\" class=\"data row0 col1\" >0.857955</td>\n",
       "                        <td id=\"T_2fe634be_d5cf_11ec_b60b_2016b948faacrow0_col2\" class=\"data row0 col2\" >0.901381</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ef3f4bbdc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Classification Report"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       331\n",
      "           1       0.86      0.86      0.86       176\n",
      "\n",
      "    accuracy                           0.90       507\n",
      "   macro avg       0.89      0.89      0.89       507\n",
      "weighted avg       0.90      0.90      0.90       507\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = classify_by_error(test_MSEs, optimal_threshold_denoising)\n",
    "matrix = confusion_matrix(y_test, predictions)\n",
    "class_accuracies = matrix.diagonal()/matrix.sum(axis=1)\n",
    "acc_df = pd.DataFrame({\n",
    "    'Inliers Accuracy': [class_accuracies[0]], \n",
    "    'Outliers Accuracy': [class_accuracies[1]], \n",
    "    'Overall Accuracy': [accuracy_score(y_test, predictions)]\n",
    "})\n",
    "\n",
    "display(Markdown(f'#### Best Threshold {optimal_threshold_denoising:.2f}, F1 Score {optimal_f1_denoising:.2f}'))\n",
    "display(acc_df.style.hide_index())\n",
    "display(Markdown(f'##### Classification Report'))\n",
    "print(classification_report(y_test, predictions))\n",
    "plot_confusion_matrix(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Variational AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Altered training, evaluation, and grid search functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch_VAE(model: nn.Module, optimizer: torch.optim.Optimizer, criterion: nn.MSELoss, train_loader: DataLoader):\n",
    "    '''\n",
    "    Train one epoch of the model on training dataset batched by the train_loader.\n",
    "    \n",
    "    :param nn.Module model: model on which we perform one training epoch\n",
    "    :param torch.optim.Optimizer optimizer: optimizer, e.g. ADAM or SGD\n",
    "    :param nn.MSELoss criterion: loss function used for training\n",
    "    :param DataLoader train_loader: data object for batching training set\n",
    "    :returns: an average loss on the training dataset\n",
    "    '''\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, _ = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs.float())\n",
    "        loss = ((outputs.float() - inputs.float()) ** 2).mean() + model.kl\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_VAE(model: nn.Module, model_name: str, optimizer: torch.optim.Optimizer, criterion: nn.MSELoss, \n",
    "                    train_loader: DataLoader, val_loader: DataLoader, nr_of_epochs: int = 100, verbose: bool = True):\n",
    "    '''\n",
    "    Train the specified model, and evaluate on validation data.\n",
    "        \n",
    "    :param nn.Module model: model being trained\n",
    "    :param str model_name: model name, e.g. denoising_autoencoder\n",
    "    :param torch.optim.Optimizer optimizer: optimizer, e.g. ADAM or SGD\n",
    "    :param nn.MSELoss criterion: loss function used for training\n",
    "    :param DataLoader train_loader: data object for batching the training set\n",
    "    :param DataLoader val_loader: data object for batching the validation set\n",
    "    :param int nr_of_epochs: number of training epochs\n",
    "    :param bool verbose: determining whether training and validation losses should be printed\n",
    "    '''\n",
    "    best_loss = 10**12\n",
    "    best_model, model_path, best_epoch = None, None, None\n",
    "\n",
    "    for epoch in range(nr_of_epochs):\n",
    "        model.train()\n",
    "        train_loss = train_one_epoch_VAE(model, optimizer, criterion, train_loader)\n",
    "        model.eval()\n",
    "\n",
    "        # performance on validation set\n",
    "        with torch.no_grad():\n",
    "            valid_loss = 0.0\n",
    "            for i, data in enumerate(val_loader):\n",
    "                inputs, _ = data\n",
    "                outputs = model(inputs.float())\n",
    "                loss = ((outputs.float() - inputs.float()) ** 2).mean() + model.kl\n",
    "                valid_loss += loss.item()\n",
    "            valid_loss = valid_loss / len(val_loader)\n",
    "\n",
    "            # logging at each Nth epoch\n",
    "            if verbose and (epoch + 1) % 20 == 0:\n",
    "                print(f'epoch {epoch + 1}; train loss: {train_loss}; valid loss: {valid_loss}')\n",
    "\n",
    "            # remember model with the best validation loss\n",
    "            if valid_loss < best_loss:\n",
    "                best_loss = valid_loss\n",
    "                best_model = model.state_dict()\n",
    "                best_epoch = epoch + 1\n",
    "\n",
    "    # save the overall best model\n",
    "    if verbose:\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        os.makedirs('models/', exist_ok=True)\n",
    "        model_path = f'models/model_{model_name}_{timestamp}_epoch{best_epoch}'\n",
    "        torch.save(best_model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_testset_VAE(model: nn.Module, testset: np.ndarray, test_labels: np.ndarray, verbose: bool = True) -> Tuple[pd.DataFrame, np.ndarray]:\n",
    "    '''\n",
    "    Evaluate testing data on the model, calculate reconstruction error, print statistics on inliers and outliers\n",
    "        \n",
    "    :param nn.Module model: model being evaluated\n",
    "    :param np.ndarray testset: testing inputs\n",
    "    :param np.ndarray test_labels: ground-truth labels\n",
    "    :param bool verbose: determining whether training and validation losses should be printed\n",
    "    :returns: dataframe with reconstruction errors and classes, reconstrution errors\n",
    "    '''\n",
    "    testset_tensor = torch.tensor(testset).float()\n",
    "    reconstructed_test = model(testset_tensor)\n",
    "    mse_test = torch.mean((reconstructed_test.detach() - testset_tensor) ** 2, axis=1) + model.kl.detach()\n",
    "    error_df = pd.DataFrame({'Reconstruction Error': mse_test, 'class': y_test})\n",
    "    \n",
    "    if verbose:\n",
    "        display(error_df[error_df['class'] == 0].describe())\n",
    "        display(error_df[error_df['class'] == 1].describe())\n",
    "    return error_df, mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_test_model_VAE(ModelClass: Type[nn.Module], hidden_sizes: List[int], latent_size: int, model_name: str,\n",
    "                              batch_size: int, learning_rate: float, seed: int) -> Tuple[float, float]:\n",
    "    '''\n",
    "    Train and evaluate model with concrete hyperparameters, try threshold grid.\n",
    "    \n",
    "    :param Type[nn.Module] ModelClass: class of model to be trained\n",
    "    :param List[int] hidden_sizes: list determining number of hidden layers and their sizes\n",
    "    :param int latent_size: size of the latent space\n",
    "    :param str model_name: name of the model architecture\n",
    "    :param int batch_size: batch size for training and validation\n",
    "    :param float learning_rate: learning rate for the optimizer\n",
    "    :param int seed: random seed for PyTorch\n",
    "    :returns: best MSE threshold, best F1 score\n",
    "    '''\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, worker_init_fn=seed_worker, shuffle=False)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, worker_init_fn=seed_worker, shuffle=False)\n",
    "    \n",
    "    seed_all(seed)\n",
    "    model = ModelClass(hidden_sizes, latent_size)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    train_model_VAE(model=model, model_name=model_name, optimizer=optimizer, criterion=criterion,\n",
    "                    train_loader=train_loader, val_loader=val_loader, nr_of_epochs=200, verbose=False)\n",
    "    \n",
    "    df, MSEs = eval_on_testset_VAE(model, X_test, y_test, verbose=False)\n",
    "    threshold, f1 = try_threshold_grid(MSEs, y_test, model_name, start=0.1, stop=5.0, num_thresholds=50, verbose_lvl=0)\n",
    "    return threshold, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_VAE(ModelClass: Type[nn.Module], model_name: str, hidden_sizes_ls: List[List[int]], latent_sizes: List[int],\n",
    "                    batch_sizes: List[int], learning_rates: List[float], seeds: List[int]):\n",
    "    '''\n",
    "    Try out grid of hyperparameters constructed as a cartesian product of the given values, \n",
    "    return the best parameters according to the model's F1 score.\n",
    "    \n",
    "    :param Type[nn.Module] ModelClass: class of model to be trained\n",
    "    :param str model_name: name of the model architecture\n",
    "    :param List[List[int]] hidden_sizes_ls: list of lists determining number of hidden layers and their sizes\n",
    "    :param List[int] latent_sizes: sizes of the latent space\n",
    "    :param List[int] batch_sizes: batch sizes for training and validation\n",
    "    :param List[float] learning_rates: learning rates for the optimizer\n",
    "    :param List[int] seeds: random seeds for PyTorch\n",
    "    :returns: best hyperparameters, best F1 score\n",
    "    '''\n",
    "    best_f1 = 0.0\n",
    "    best_model_params = None\n",
    "    \n",
    "    cartes_product = list(itertools.product(hidden_sizes_ls, latent_sizes, batch_sizes, learning_rates, seeds))\n",
    "    for hidden_sizes, latent_size, batch_size, learning_rate, seed in tqdm(cartes_product):\n",
    "        threshold, f1 = train_eval_test_model_VAE(ModelClass, hidden_sizes, latent_size, model_name, batch_size, learning_rate, seed)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_model_params = hidden_sizes, latent_size, batch_size, learning_rate, seed, threshold\n",
    "    return best_model_params, best_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self, hidden_sizes: List[int], latent_size: int):\n",
    "        super(VariationalAutoEncoder, self).__init__()\n",
    "        \n",
    "        self.encLayers = [nn.Linear(INPUT_SIZE, hidden_sizes[0]), nn.ReLU()]\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "            self.encLayers += [nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.ReLU()]\n",
    "        self.encLinMu = nn.Linear(hidden_sizes[-1], latent_size)\n",
    "        self.encLinSigma = nn.Linear(hidden_sizes[-1], latent_size)\n",
    "        self.normal = torch.distributions.Normal(0, 1)\n",
    "        self.kl = 0\n",
    "\n",
    "        self.decLayers = [nn.Linear(latent_size, hidden_sizes[-1]), nn.ReLU()]\n",
    "        for i in range(1, len(hidden_sizes)):\n",
    "            self.decLayers += [nn.Linear(hidden_sizes[-i], hidden_sizes[-i-1]), nn.ReLU()]\n",
    "        self.decLayers += [nn.Linear(hidden_sizes[0], INPUT_SIZE)]        \n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        for layer in self.encLayers:\n",
    "            x = layer(x)\n",
    "        mu = self.encLinMu(x)\n",
    "        sigma = torch.exp(self.encLinSigma(x))\n",
    "        x = mu + sigma * self.normal.sample(mu.shape)\n",
    "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).mean()\n",
    "\n",
    "        for layer in self.decLayers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 108/108 [14:19<00:00,  7.96s/it]\n"
     ]
    }
   ],
   "source": [
    "best_model_params_vae, best_f1_vae = grid_search_VAE(ModelClass=VariationalAutoEncoder,\n",
    "                                                     model_name='variational_autoencoder',\n",
    "                                                     hidden_sizes_ls=[[16], [18], [18, 16]],\n",
    "                                                     latent_sizes=[12, 14],\n",
    "                                                     batch_sizes=[32, 64, 128], \n",
    "                                                     learning_rates=[1e-3, 1e-2], \n",
    "                                                     seeds=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Best Parameters"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_b3a22cca_d5d5_11ec_bd2f_2016b948faac\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Hidden Sizes</th>        <th class=\"col_heading level0 col1\" >Latent Size</th>        <th class=\"col_heading level0 col2\" >Batch Size</th>        <th class=\"col_heading level0 col3\" >Learning Rate</th>        <th class=\"col_heading level0 col4\" >Seed</th>        <th class=\"col_heading level0 col5\" >Threshold</th>        <th class=\"col_heading level0 col6\" >F1 Score</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_b3a22cca_d5d5_11ec_bd2f_2016b948faacrow0_col0\" class=\"data row0 col0\" >[18]</td>\n",
       "                        <td id=\"T_b3a22cca_d5d5_11ec_bd2f_2016b948faacrow0_col1\" class=\"data row0 col1\" >12</td>\n",
       "                        <td id=\"T_b3a22cca_d5d5_11ec_bd2f_2016b948faacrow0_col2\" class=\"data row0 col2\" >32</td>\n",
       "                        <td id=\"T_b3a22cca_d5d5_11ec_bd2f_2016b948faacrow0_col3\" class=\"data row0 col3\" >0.001000</td>\n",
       "                        <td id=\"T_b3a22cca_d5d5_11ec_bd2f_2016b948faacrow0_col4\" class=\"data row0 col4\" >2</td>\n",
       "                        <td id=\"T_b3a22cca_d5d5_11ec_bd2f_2016b948faacrow0_col5\" class=\"data row0 col5\" >1.700000</td>\n",
       "                        <td id=\"T_b3a22cca_d5d5_11ec_bd2f_2016b948faacrow0_col6\" class=\"data row0 col6\" >0.861789</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ef3f556730>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params_df_vae = pd.DataFrame([list(best_model_params_vae) + [best_f1_vae]], columns=['Hidden Sizes', 'Latent Size', 'Batch Size', 'Learning Rate', 'Seed', 'Threshold', 'F1 Score'])\n",
    "display(Markdown('#### Best Parameters'))\n",
    "display(best_params_df_vae.style.hide_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I run again the model with the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_vae = best_model_params_vae[2]\n",
    "hidden_sizes_vae = best_model_params_vae[0]\n",
    "latent_size_vae = best_model_params_vae[1]\n",
    "learning_rate_vae = best_model_params_vae[3]\n",
    "seed_vae = best_model_params_vae[4]\n",
    "\n",
    "train_dataloader_vae = DataLoader(train_data, batch_size=batch_size_vae, worker_init_fn=seed_worker, shuffle=False)\n",
    "val_dataloader_vae = DataLoader(val_data, batch_size=batch_size_vae, worker_init_fn=seed_worker, shuffle=False)\n",
    "\n",
    "seed_all(seed_vae)\n",
    "variational_ae = VariationalAutoEncoder(hidden_sizes=hidden_sizes_vae, latent_size=latent_size_vae)\n",
    "\n",
    "optimizer_vae = torch.optim.Adam(variational_ae.parameters(), lr=learning_rate_vae)\n",
    "criterion_vae = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; train loss: 1.1857427814427544; valid loss: 1.1831059455871582\n",
      "epoch 40; train loss: 1.1772580742835999; valid loss: 1.1772691673702664\n",
      "epoch 60; train loss: 1.1774289222324597; valid loss: 1.1755044195387099\n",
      "epoch 80; train loss: 1.1802274269216202; valid loss: 1.175316572189331\n",
      "epoch 100; train loss: 1.176976584336337; valid loss: 1.1717075374391344\n",
      "epoch 120; train loss: 1.176732739981483; valid loss: 1.169948485162523\n",
      "epoch 140; train loss: 1.1805214461158304; valid loss: 1.169108231862386\n",
      "epoch 160; train loss: 1.1757236088023466; valid loss: 1.1730745236078899\n",
      "epoch 180; train loss: 1.178123744095073; valid loss: 1.1774977445602417\n",
      "epoch 200; train loss: 1.1740533078418058; valid loss: 1.1730737156338162\n"
     ]
    }
   ],
   "source": [
    "train_model_VAE(model=variational_ae, model_name='variational_autoencoder', optimizer=optimizer_vae, criterion=criterion_vae,\n",
    "                train_loader=train_dataloader_vae, val_loader=val_dataloader_vae, nr_of_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reconstruction Error</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>331.000000</td>\n",
       "      <td>331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.252344</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.951236</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.102357</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.564487</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.996288</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.972276</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>197.650070</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reconstruction Error  class\n",
       "count            331.000000  331.0\n",
       "mean               2.252344    0.0\n",
       "std               10.951236    0.0\n",
       "min                0.102357    0.0\n",
       "25%                0.564487    0.0\n",
       "50%                0.996288    0.0\n",
       "75%                1.972276    0.0\n",
       "max              197.650070    0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reconstruction Error</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26.376417</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>55.906544</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.332025</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.609365</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.143871</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.133160</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>426.904022</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reconstruction Error  class\n",
       "count            176.000000  176.0\n",
       "mean              26.376417    1.0\n",
       "std               55.906544    0.0\n",
       "min                0.332025    1.0\n",
       "25%                5.609365    1.0\n",
       "50%               10.143871    1.0\n",
       "75%               22.133160    1.0\n",
       "max              426.904022    1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df, test_MSEs = eval_on_testset(denoising_ae, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Model: variational_autoencoder, trying 50 thresholds from [0.1, 5.0]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "For more detail, call the function with `verbose_lvl=2`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimal_threshold_vae, optimal_f1_vae = try_threshold_grid(test_MSEs, y_test, 'variational_autoencoder', start=0.1, stop=5.0, num_thresholds=50, verbose_lvl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Best Threshold 4.60, F1 Score 0.86"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_138b0ce7_d5dd_11ec_bd2f_2016b948faac\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Inliers Accuracy</th>        <th class=\"col_heading level0 col1\" >Outliers Accuracy</th>        <th class=\"col_heading level0 col2\" >Overall Accuracy</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_138b0ce7_d5dd_11ec_bd2f_2016b948faacrow0_col0\" class=\"data row0 col0\" >0.924471</td>\n",
       "                        <td id=\"T_138b0ce7_d5dd_11ec_bd2f_2016b948faacrow0_col1\" class=\"data row0 col1\" >0.857955</td>\n",
       "                        <td id=\"T_138b0ce7_d5dd_11ec_bd2f_2016b948faacrow0_col2\" class=\"data row0 col2\" >0.901381</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ef3f5da760>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Classification Report"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       331\n",
      "           1       0.86      0.86      0.86       176\n",
      "\n",
      "    accuracy                           0.90       507\n",
      "   macro avg       0.89      0.89      0.89       507\n",
      "weighted avg       0.90      0.90      0.90       507\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = classify_by_error(test_MSEs, optimal_threshold_vae)\n",
    "matrix = confusion_matrix(y_test, predictions)\n",
    "class_accuracies = matrix.diagonal()/matrix.sum(axis=1)\n",
    "acc_df = pd.DataFrame({\n",
    "    'Inliers Accuracy': [class_accuracies[0]], \n",
    "    'Outliers Accuracy': [class_accuracies[1]], \n",
    "    'Overall Accuracy': [accuracy_score(y_test, predictions)]\n",
    "})\n",
    "\n",
    "display(Markdown(f'#### Best Threshold {optimal_threshold_vae:.2f}, F1 Score {optimal_f1_vae:.2f}'))\n",
    "display(acc_df.style.hide_index())\n",
    "display(Markdown(f'##### Classification Report'))\n",
    "print(classification_report(y_test, predictions))\n",
    "plot_confusion_matrix(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have compared three different autoencoder architectures for outlier detection:\n",
    "1. undercomplete autoencoder\n",
    "2. denoising autoencoder\n",
    "3. variational autoencoder\n",
    "\n",
    "For each of them, I tuned the following hyperparameters in a grid search:\n",
    "- Batch size\n",
    "- Learning rate\n",
    "- Hidden layer count and dimension\n",
    "- Latent space dimension\n",
    "- Thresholds on reconstruction errors from interval.\n",
    "\n",
    "I have chosen the best classifier based on the F1-score, where negative class is composed of inliers and positive class is composed of outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you can find the best hyper-parameters of the architectures. As for the layers, only encoder architecture is shown, since decoder contains almost the same layers, just reversed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Hidden Layers</th>\n",
       "      <th>Latent Space Size</th>\n",
       "      <th>Seed</th>\n",
       "      <th>MSE Threshold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Architecture</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Undercomplete Autoencoder</th>\n",
       "      <td>0.853868</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>[18]</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Denoising Autoencoder</th>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>[18, 16]</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variational Autoencoder</th>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>[18]</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           F1 Score  Learning Rate  Batch Size Hidden Layers  \\\n",
       "Architecture                                                                   \n",
       "Undercomplete Autoencoder  0.853868          0.010          32          [18]   \n",
       "Denoising Autoencoder      0.857955          0.001          64      [18, 16]   \n",
       "Variational Autoencoder    0.857955          0.001          32          [18]   \n",
       "\n",
       "                           Latent Space Size  Seed  MSE Threshold  \n",
       "Architecture                                                       \n",
       "Undercomplete Autoencoder                 14     1            0.6  \n",
       "Denoising Autoencoder                     12     0            4.6  \n",
       "Variational Autoencoder                   12     2            4.6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_df = pd.DataFrame({'Architecture': ['Undercomplete Autoencoder', 'Denoising Autoencoder', 'Variational Autoencoder'],\n",
    "                          'F1 Score': [optimal_f1_under, optimal_f1_denoising, optimal_f1_vae],\n",
    "                          'Learning Rate': [learning_rate_uae, learning_rate_dae, learning_rate_vae],\n",
    "                          'Batch Size': [batch_size_uae, batch_size_dae, batch_size_vae], \n",
    "                          'Hidden Layers': [hidden_sizes_uae, hidden_sizes_dae, hidden_sizes_vae],\n",
    "                          'Latent Space Size': [latent_size_uae, latent_size_dae, latent_size_vae],\n",
    "                          'Seed': [seed_uae, seed_dae, seed_vae],\n",
    "                          'MSE Threshold': [optimal_threshold_under, optimal_threshold_denoising, optimal_threshold_vae],\n",
    "                         })\n",
    "result_df = result_df.set_index('Architecture')\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bakalarka",
   "language": "python",
   "name": "bakalarka"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
